1)
    list of commands:
    - sudo -- super user do. If you prefix “sudo” with any command, it will run that command with elevated privileges which allows a user with proper permissions to execute a command as superuser.
    - ls
    - cd: Change directory. Allow the user to change between file directories.
            cd --> Will change to the home directory
            cd - --> Will switch to the old directory
            cd ~ --> Will move to the home directory
                $cd ~/Linux_System_Prog
    - pwd: Will print the current working directory
    - touch: Allows user to make files from the command line Interface
    - rm: This command is used to remove files
    - mkdir: Allows user to create a new directory.
    - rmdir: Allows user to remove a directory
    - mv: Allows user to move file from one place to another
    - cp: $cp file1 file2
    - clear: clear command will take the user back to the start prompt of directory you are currently operating in
    - man: Use to show the manual of the command passed
            $ man man
            man has various sections, same command can be executable program, shell command, system call, library call, etc., so to differentiate we can specify. man <number> <command>. e.g., man 2 man. Number can be found using [man man].
    - find: $find <path> -name 'filename'. $find / -name "*conf" -mtime 7.
    - echo: It prints the strings that are passed as arguments to the standard output.
            To append to a file
            $ echo "Test Page" >> testpage
    - cat: cat stands for concatenate
            Display the contents of the file. $cat /etc/passwd
            Create a file with cat command. cat > file.txt. Will create a file 'file.txt' and allows user to type the content on the console.
    - more: view contents of text file one page at a time.
    - less: linux utility which can be used to read contents of text file one page(one screen) per time.
    - head: outputs the first part (the head) of a file or files. head, by default, prints the first 10 lines.
    - tail: prints the last few number of lines (10 lines by default) of a certain file, then terminates.
    - pipe | : Linux systems allow stdout of a command to be connected to stdin of another command. You can make it do so by using the pipe character ‘|’. command_1 | command_2 | command_3 | .... | command_N. $cat sample2.txt | head -7 | tail -5.
    - tee : reads from the standard input and writes to both standard output and one or more files at the same time. $df -h | tee disk_usage.txt
    - ps : Provides information about currently running processes. daemon can be created by &. generally ssh runs as daemon. [./hello &] will run hello executable as daemon. We can kill by [ kill %<number> ] given by jobs command.
    - grep: It searches for the given string in the specified file.
    - wc: word count. [ wc filename.txt ] will show number of lines, words and bytes
    - top : displays the top processes in the system ( by default sorted by cpu usage ).
    - df : Displays the file system disk space usage.
    - uname : displays important system information:Kernel name, Host name, Kernel release number, Processor type, etc.,
    - date : Set the system date.
    - ping : Check network connectivity
    - which : Used to locate the executable file associated with the given command by searching it in the path environment variable.
    - whoami : whoami command print the name of current user
    - lsof : lsof mean List of all open files.
    - history
    - time: Find time taken by a command/program on Linux Shell
            real: Total end to end time taken by program/command
            user: Time taken in user mode.
            sys: Time taken in kernel mode

2)
    - tree -L 1 /. show only the 1st level of the directory tree starting at root (/).

    In Linux however, the root of the filesystem doesn’t correspond with a physical device or location, it’s a logical location of simply “/”.
        / (Root) : Every single file and directory starts from the root directory
        /boot :  Contains files required for starting your system. Boot loader files, e.g., kernels, initrd. config-* - contains kernel configuration settings. e.g. if we want to know if HID is enable, we can run [ cat /boot/config-`uname -r`-generic | grep HIDRAW.
                    - initrd.img-* - initrd - initial ram disk is loaded by the kernel at boot time, it loads temporary file system into RAM at the time of booting, before actually mounting actual file system
                    - vmlinuz-* - virtual memory Linux kernel zipped. vmlinuz is a compressed Linux Kernel image which is used at the time of booting Linux operating system. vmlinuz used by Intel. Arm uses uimage if we use u-boot. x86, grub uses vmlinuz. When grub starts, it uncompresses this image and starts loading.
                    - System.map-* - the System.map file is a symbol table used by the kernel. A symbol table is a look-up between symbol names ( variable or function ) and their addresses in memory. It is useful when kernel panics it will print various address, then we can use directly this system.map file to convert those addresses into function or variable names.
                    - grub/grub.conf - This file is used for boot loader grub to load grub related configuration. If we want to modify any configuration in grub bootloader, we use this.
        - /bin folder: bin stands for binary which means an executable file. This folder contains basic commands such as cat, chmod, chgrp, chown, date, dir, dd, df, ln, mv, echo.
        - /sbin: stands for system binaries or super user binaries. It contains commands that need to be available at the very beginning of the OS initialization and at the shutdown end too. Contains commands required for changing system properties or system level settings such as disk management, network management etc. e.g. fsck, root, init, ifconfig
        - /usr is generally for user / administrator added binaries.
                /usr/bin: commands which are not installed locally should be placed in this directory. Eg. vi, atq, bc, awk, cal, cmp, dig, diff, du, env, find, free, ftp, gcc, groups, id, info iostat, last, lsof, md5sum, nmap, rar, seq, tail, top.
        - /usr/sbin: contains non-vital system utilities that are used after booting (i.e., starting the system) by the system administrator. Eg.  adduser, chroot, groupadd, grub related commands, tcpdump. Also contains some daemons, which are programs that run silently in the background: Eg. bluetoothd, dropbear
        - /usr/local is a place where files built by the system administrator are placed
            - /usr/local/bin: Binaries for programs local to the site.
            - /usr/local/sbin: Locally installed programs for system administration
        - /dev: Linux/Unix treats hardware devices too as files. All hardware files are present in /dev(Device ) folder. e.g., /dev/null. Many of these are generated at boot time or even on the fly.
                character devices example:
                    /dev/lp0 represents the first printer port
                    /dev/ttyS0 represents the first serial port
                Block devices:
                    /dev/hd* represents hard disk drives.
                    /dev/sd* represents SCSI devices
        - /etc: Contains system-wide configuration files. Contains configuration files required by all programs. This also contains startup and shutdown shell scripts used to start/stop individual programs.
            Example: /etc/resolv.conf, /etc/logrotate.conf. [ cat /etc/passwd ]
            /etc/hostname -- Contains the hostname of your machine
            /etc/modules -- List of modules to be loaded at startup.
            /etc/hosts -- The hosts file is used to map hostname to IP Address
            /etc/fstab -- this file automatically mounts filesystems that are spread across multiple drives or separate partitions. This file is checked when the system boots and filesystems are mounted. During boot, kernel reads this file and mounts all filesystem listed here. e.g. [ cat /etc/fstab ] and the verify same UUID using [ blkid /dev/<filesystem> ]
            /etc/passwd - user details
        - /home: for all users to store their personal files. For example, if your user name is bob, you have a home folder located at /home/bob. Each user only has write access to their own home folder and must obtain elevated permissions (become the root user) to modify other files on the system. [ echo $HOME ] gives path of home folder for a user. If we become root by su or sudo -s command the  above command will display root home folder.
        - /root: Home directory of root user
        - /lib: Libraries essential for the binaries in /bin/ and /sbin/. /lib/modules -- All loadable kernel modules are stored in this directory. /lib<qual> (lib32, lib64 etc): 32bit, 64 bit libs of the same name. A 64-bit system may have compatibility for 32-bit binary.
        -/media: media directory is where external storage will be automatically mounted when you plug it in and try to access it. For example, when you insert a CD into your Linux system, a directory will automatically be created inside the /media directory.
        - /mnt: A directory for temporarily mounted filesystems. For example, if youre mounting a Windows partition to perform some file recovery operations, you might mount it at /mnt/windows. Eg. iso files: mount -t iso9660 -o loop path/to/image.iso /mnt/
        - /tmp: Temporary files. Often not preserved between system reboots, and may be severely size restricted.
        - /run: /run is another new directory. System processes use it to store temporary data for their own nefarious reasons. Mostly contains pid related information.
        - /srv: The /srv directory contains data for servers ( such as Apache, FTP, web server etc. ). If you are running a web server from your Linux box, your HTML files for your sites would go into /srv/http (or /srv/www). If you were running an FTP server, your files would go into /srv/ftp.
        - var: /var contains variable data files. This includes spool directories and files, administrative and logging data, and transient and temporary files. /var/log contains log files for differenctt applications. dmesg is also located here. /var/mail contains users emails. /var/run holds a lot status and parameter information of actively running process daemons.
        - opt: third party installers
        - lost+found: fsck command is used to recover these files. Any file to be recovered is kept in this folder
        - Proc: These are virtual file systems most used in device drivers. It means that files are not present in hard disk or in any media storage. these are stored in RAM and whenever we start system, files will be created in RAM. e.g. if we do [ ls -l proc/cmdline ], size will show as 0. but [ cat proc/cmdline ] will give print the content. Since it has content, it should have some size. But since it is not stored in hard dsik/storage/memory, ls shows 0 size. difference between virtual file and actual file:
                virtual file has 0 size
                actual file has some size
            proc contains special files that represent system and process information. quite a lot of system utilities are simply calls to files in this directory.
                'lsmod' is the same as 'cat /proc/modules'. We can verify it by [ strace lsmod | grep modules ]
                'lspci' is a synonym for 'cat /proc/pci'. We can verify it by [ strace lspci ] tahat it uses sys filesystem.
                /proc/meminfo contains a bunch of information about your system's memory
                /proc/uptime uptime information (in seconds).
                /proc/partitions detailed info about partitions available to the system.
                /proc/cmdline kernel command line information.
            The /proc filesystem maps mostly to the process table. It also raised the issue that /proc was SUPPOSED to be for the process table. So they added another instance, and named it sys aimed to hold system information.
        - sys: sysfs is used by programs such as udev to access device and device driver information. To get the a network card's MAC address. cat /sys/class/net/eth0/address.
    All process related informations are present in proc filesystem. [ ls /proc ]. Whereas, all hardware related informations are present in sys filesystem. [ ls /sys ]. Whenever we create a new module, new folder will get created in /sys/module directory. Whenever we add a new device, new folder will get created in /sys/dev or /sys/bus directory.

3)
    GCC Compilation Process:For example, a "gcc -o hello hello.c" is carried out as follows:
        1. Pre-processing:
            joining continued lines (lines ending with a \), Removal of Comments, Expansion of Macros, Expansion of the included files. The output of this step is a "pure" C file without pre-processor directives.
        2. Compilation:
            Check C program for syntax errors. Translate the file into intermediate code i.e. in assembly language. Optionally optimize the translated code for better performance. Removing unused variables and subroutines.
        3. Assembly:
            During this stage, an assembler is used to translate the assembly instructions to object code. The output consists of actual instructions to be run by the target processor. The contents of this file is in a binary format and can be inspected using hexdump or od by running either one of the following commands:
                $hexdump hello.o
                $od -c hello.o
            At this phase, only existing code is converted into machine language, the function calls like printf() are not resolved. The object code generated in the assembly stage is composed of machine instructions that the processor understands but some pieces of the program are out of order or missing.
        4. Linker:
            To produce an executable program, the existing pieces have to be rearranged and the missing ones filled in. This process is called linking. The result of this stage is the final executable program. [ file hello ] will give info about actual executable. linker will combine all files' .data .txt etc sections in one executable file as combined sections. An object and executable come in several formats:
                - ELF (Executable and Linking Format) is used on Linux. ELF is format used by Linux to store object, executable, shared library and kernel object files.
                - COFF (Common Object-File Format) is used on Windows systems.


    ldd tool will print the shared libraries required by each program:
        $ldd main
            linux-vdso.so.1 =>  (0x00007ffd241f8000)
            libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd939b4c000)
            /lib64/ld-linux-x86-64.so.2 (0x000055ab46461000)
    The above output indicates that the main executable depends on three libraries. The first library is required for making system calls. The second library is C Library. The third shared library is the one which loads all the other shared libraries required by the executable.

    Extracting Information from .o and executable binary files: [ $readelf --symbols hello.o ] will show us symbols in the object file. objdump can also be used. [ objdump -D hello.o ] dissassembles the file.

    Linux generated executable will not work on Windows even if machine architecture is same. Because, Linux executable file format is ELF but Windows executable file format is COFF.

    Instruction set Architecture provides the software below information:
        What instructions are available?
        How many and what kind of registers are available?
        Memory: How to access contents
        Software compiled for one ISA will not run on hardware with a different ISA

    Application Binary Interface (ABI): ABI = ISA + More.
        ABI Handles the following:
            Calling Conventions
            How function arguments are passed
            How function return values are retrieved. for example, whether all parameters are passed on the stack or some are passed in registers
            which registers are used for which function parameters
            whether the first function parameter passed on the stack is pushed first or last onto the stack

4-5)
    __attribute__((constructor)) syntax : This particular GCC syntax, when used with a function, executes the same function at the startup of the program, i.e before main() function.
    __attribute__((destructor)) syntax : This particular GCC syntax, when used with a function, executes the same function just before the program terminates through _exit, i.e after main() function.

    Linux Library Types:
        1. Static libraries (.a): Library of object code which is linked with, and becomes part of the application. Static linking is the process of copying all library modules used in the program into the final executable image. This is performed by the linker and it is done as the last step of the compilation process. The linker combines library routines with the program code in order to resolve external references, and to generate an executable image suitable for loading into memory.
                $ gcc hello.c -o hello --static
                run [ ldd ./statichello ] and will give you a output that it is not a dynamic executable.
                [ size statichello ] will give different section sizes. compared to dynamic library, size is huge.
                [ strace statichello ] will list all system calls made and those are less compared to dynamic library.
            Advantages:
                - Faster than shared libraries because a set of commonly used object files is put into a single library executable file.
                - Once everything is bundled into your application, you don’t have to worry that the client will have the right library (and version) available on their system.
            Disadvantages:
                - Executable size is larger
                - If any changes have to be made to the static library (any bug in the static library), it has to be recompiled and relinked back to the application
            When to use static libraries:
                1. When  you aren't sure whether the correct version of a library will be available at runtime
                2. You were testing a new version of a library that you don't yet want to install as shared.
        2. Dynamically linked shared object libraries (.so): There is only one form of this library but it can be used in two ways. Assembler output is obj files. Linker joins object files into one executable. Loader brings executable into memory and starts execution. When using a static linking, the linker finds the bits that the program modules need, and physically copies them into the executable output file that it generates. For dynamic linking, it doesn't copy instead it leaves a note in the executable saying `when this program is run, it will first have to load this library'. Dynamic linking can occur when executable is first loaded and run (load‐time linking). Dynamic linking can also occur after program has begun (run‐time linking).
                    Advantages of Dynamic Linking:
                        - Dynamic libraries provide a means to use code that can be loaded anywhere in the memory. Dynamic library has relocatable address. Once loaded, the library code can be used by any number of programs. This way the size of programs using dynamic library can be kept low as a lot of code is kept common in form of a shared library
                    run [ ldd dynamichello ] and it will give list of libraries dependent on
                    [ strace dynamichello ] will list all system calls made and those are large.
            1. Dynamically linked at run time. The libraries must be available during compile/link phase. The shared objects are not included into the executable component but are tied to the execution.
            2. Dynamically loaded/unloaded and linked during execution. Using the dynamic linking loader system functions.
        How to create the dynamic library:
            1: Create object files using the below command
                $ gcc -fPIC -c *.c
                the -fPIC flag stands for Position Independent Code, a characteristic required by shared libraries
            2: Create the library
                $ gcc -shared -Wl,-soname,libarith.so -o libarith.so *.o
                The -shared key tells the compiler to produce a shared object which can then be linked with other objects to form an executable.

    nm lists symbols ( variables and functions ) from object files.

6-7)
https://github.com/prnjl99/Bare_metal_embedded_development/blob/main/build_scripts/gdb_cmd

8)
    A “core dump” is a snapshot of memory at the instant the program crashed, typically saved in a file called “core”. The core contains the memory contents of the process at the point of the seg-fault including its:
        code segment, data segment, stack segment and heap segment.
    Core dumps allow a user to save a crash for later or off-site analysis, or comparison with other crashes. if we run [ gcc source_code.c -o source_code -g ] and then run [ ./source_code ], then it will print segmentation fault ( core dumped ).

    Valgrind is a debugging tool & is a wrapper around various tools for debugging and profiling. Best tool out of these is MemCheck that is used to find out memory leaks etc.
        $valgrind --tool=memcheck --leak-check=yes  ./1
    Catches common memory bugs (UB) on dynamically allocated memory regions
        Using Uninitialized Variables
        Out-of-bounds memory access(read/write underflow/overflow bugs)
        Use-after-free/use after return(out of scope) bugs
        Double free
        Leakage

9)
    Electric Fence helps you detect overruns the boundaries of a malloc()memory allocation &  software that touches a memory allocation that has been released by free(). Electric Fence replaces the C library's normal malloc() function with a version that allocates the requested memory and (usually) allocates a section of memory immediately after this, which the process is not allowed to access! Electric Fence creates a virtual fence around each allocated buffer in a way that any illegal memory access results in a segmentation fault.

    Standard functions can be divided in two main categories :-
        1. Library function calls.
            The functions which are a part of standard C library are known as Library functions. E.g. strcmp(), strlen()
        2. System function calls.
            The functions which change the execution mode of the program from user mode to kernel mode are known as system calls. E.g. socket(), open(), read() , write()
    A library function is linked to the user program and executes in user space but a system call is not linked to a user program and executes in kernel space. how to find if given given function is library call or system call ? if we do [ man printf ] and we see 1, it means it is executable. we can run [ man man ] to find section numbers and what they corresponds to. We can see 2 is for system call and 3 is for library calls.

10)
    File Descriptors: A process may have several open files which it may be reading from and writing to. Each process has its own array to keep track of:
        - The file opened.
        - The files status (whether open for reading or writing: the file status flags )
        - The current offset within the file

    When a file is opened or created by a process the kernel assigns a position in the above array called the file descriptor. To the kernel, all open files are referred to by file descriptors. A file descriptor is a non-negative integer. When we open an existing file or create a new file, the kernel returns a file descriptor to the process. When we want to read or write a file, we identify the file with the file descriptor that was returned by open or creat as an argument to either read or write. By convention, UNIX System shells associate:
        STDIN_FILENO: file descriptor 0 with the standard input of a process,
        STDOUT_FILENO: file descriptor 1 with the standard output, and
        STDERR_FILENO: file descriptor 2 with the standard error.

    stdout is fully buffered and stderr is not buffered.

    fopen vs open in C:
        fopen
            1) fopen is a library function while open is a system call.
            2) fopen provides buffered IO which is faster compare to open which is non buffered.
            3) fopen is portable while open not portable (because open is environment ( platform - linux/windows etc. ) specific).
            4) fopen returns a pointer to a FILE structure(FILE *); open returns an integer that identifies the file.
            5) A FILE * gives you the ability to use fscanf and other stdio functions.
        open
            A file is opened or created by calling either the open function or the openat function
                #include <fcntl.h>
                int open(const char *path, int oflag, ... /* mode_t mode */ );
                int openat(int fd, const char *path, int oflag, ... /* mode_t mode */ );

    diff btween open and openat is openat takes file descriptor/at cwd.

11-12)
    int creat(const char *path, mode_t mode);
        A better way is to use the open function, as in
        open(path, O_RDWR | O_CREAT | O_TRUNC, mode);

    An open file is closed by calling the close function.
        #include <unistd.h>
        int close(int fd);
        When a process terminates, all of its open files are closed automatically by the kernel. if we use buffered I/O then data will get lost if close is not used after opening. Unbuffered I/O it may be okay.

    Data is written to an open file with the write function.
        #include <unistd.h>
        ssize_t write(int fd, const void *buf, size_t nbytes);

    Data is read from an open file with the read function.
        #include <unistd.h>
        ssize_t read(int fd, void *buf, size_t nbytes);

    Every open file has an associated ‘‘current file offset,’’ normally a non-negative integer that measures the number of bytes from the beginning of the file. Read and write operations normally start at the current file offset and cause the offset to be incremented by the number of bytes read or written. By default, this offset is initialized to 0 when a file is opened, unless the O_APPEND option is specified. An open file’s offset can be set explicitly by calling lseek.
        #include <unistd.h>
        off_t lseek(int fd, off_t offset, int whence);

    The dup system call duplicates an existing file descriptor, returning a new one that refers to the same underlying I/O object. Dup allows shells to implement commands like this:
        ls existing-file non-existing-file > tmp1  2>&1
    The 2>&1 tells the shell to give the command a file descriptor 2 that is a duplicate of descriptor 1. (i.e stderr & stdout point to same fd). Now the error message for calling ls on non-existing file and the correct output of ls on existing file show up in tmp1 file.

    An existing file descriptor is duplicated by either of the following functions
        #include <unistd.h>
        int dup(int fd);
        int dup2(int fd, int fd2);
    The new file descriptor returned by dup is guaranteed to be the lowest-numbered available file descriptor. With dup2, we can specify the value of the new descriptor of our choice with the fd2 argument.

13)
    Inodes: In Linux everything is treated as a file. (even the hardware devices). The keyboard, mouse, printers, monitor, hard disk, processes, even the directories are treated as files in Linux. Set aside the regular data, there are some other data about these files, such as their size, ownership, permissions, timestamp etc. This meta-data about a file is managed with a data structure known as an inode (index node).

    For example, the inode contains
        a list of all the blocks in which a file is stored
        the owner information for that file,
        permissions
        and all other attributes that are set for the file.

    In a sense, you could say that a file really is the inode, and names are attached to these inodes to make it easier for humans to work with them. An inode is a data structure on a traditional Unix-style file system such as ext3 or ext4. Linux extended filesystems such as ext2 or ext3 maintain an array of these inodes: the inode table. This table contains list of all files in that filesystem. The individual inodes in inode table have a unique number (unique to that filesystem), the inode number. an inode stores:
        File type: regular file, directory, pipe etc.
        Permissions to that file: read, write, execute
        Link count: The number of hard link relative to an inode
        User ID: owner of file
        Group ID: group owner
        Size of file: or major/minor number in case of some special files
        Time stamp: access time, modification time and (inode) change time
        Attributes: immutable' for example
        Access control list: permissions for special users/groups
        Link to location of file
        Other metadata about the file

    Note that inode does not store name of the file but its content only. You can display the inode data on a file or directory by using stat command. You need to indicate the name of the file. we can run [ man stat ]. stat can takefile and folder both as input.

    the name of the file is stored within the directories' information structure. directories are special files that are used to create and hold access paths to the files in the file system. A directory file is a list of directory entries, each one containing the following information:
        inode - The inode for this directory entry. This is an index into the array of inodes held in the Inode Table of the Block Group.
        name length - The length of this directory entry in bytes,
        name - The name of this directory entry.
    The first two entries for every directory are always the standard . and .. entries meaning "this directory" and "the parent directory" respectively.

    #include <sys/stat.h>
    int stat(const char *restrict pathname, struct stat *restrict buf );
    Given a pathname, the stat function returns a structure of information about the named file
    struct stat {
        mode_t st_mode; /* file type & mode (permissions) */
        ino_t st_ino; /* i-node number (serial number) */
        dev_t st_dev; /* device number (file system) */
        dev_t st_rdev; /* device number for special files */
        nlink_t st_nlink; /* number of links */
        uid_t st_uid; /* user ID of owner */
        gid_t st_gid; /* group ID of owner */
        off_t st_size; /* size in bytes, for regular files */
        struct timespec st_atim; /* time of last access */
        struct timespec st_mtim; /* time of last modification */
        struct timespec st_ctim; /* time of last file status change */
        blksize_t st_blksize; /* best I/O block size */
        blkcnt_t st_blocks; /* number of disk blocks allocated */
    };

    The biggest user of the stat functions is probably the ls -l command, to learn all the information about a file. we can verify it by running [ strace ls -l ]. The fstat function obtains information about the file that is already open on the descriptor fd.

    A link in Linux is a pointer to a file. Creating links is a kind of shortcuts to access a file. Links allow more than one file name to refer to the same file, elsewhere. Two types of links :
        1. Soft Link or Symbolic links
        2. Hard Links
        3. Nothing

    Hard Link: The basic command structure for creating a hard link is:
        $ln file.txt hard_file.txt
        SOURCE is the original file. LINK is the new file you will create that will point to the original source.
        Important Points:
            1. Hard links will have the same inode number. We can verify it by checking inode values by [ stat <filename> ]. Also check incremented link count. Unix files consist of two parts: the data part and the filename part. The data part is associated with something called an 'inode'. The inode carries the map of where the data is, the file permissions, etc. for the data.
                                                .---------------> ! data ! ! data ! etc
                                               /                 +------+ !------+
                        ! permbits, etc ! data addresses !
                        +------------inode---------------+

                    The filename part carries a name and an associated inode number.

                                        .--------------> ! permbits, etc ! addresses !
                                        /                 +---------inode-------------+
                        ! filename ! inode # !
                        +--------------------+

                    More than one filename can reference the same inode number; these files are said to be 'hard linked' together.

                    ! filename ! inode # !
                    +--------------------+
                                        \
                                         >--------------> ! permbits, etc ! addresses !
                                        /                 +---------inode-------------+
                        ! othername ! inode # !
                        +---------------------+
            so modifying one will affect other. When deleting files, the data part isn't disposed of until all the filename parts have been deleted. There's a count in the inode that indicates how many filenames point to this file, and that count is decremented by 1 each time one of those filenames is deleted. When the count makes it to zero, the inode and its associated data are deleted.
                $ stat file.txt # There is a link field in output which will be updated each time a new hard link is created
        2. Links have actual file contents
        3. Even if the original file is removed, the link will still show you the contents of the file ( because it is pointing to inode )
        4. You cannot create a hard link for a directory
        5. Hard links are only valid within the same File System. ( so creating links acrros Windows and Linux file system will not work ).

    Soft Link:
        ln -s <SOURCE> <LINK>
        SOURCE is the original file and LINK is the new file you will create that will point to the original source.

        Important Points:
            1. Soft Links will have different inode number, file size are different and permissions are also different ( verify it by [ ls -li <filename> ], first number is inode ? ).
            2. Soft link contains the path to the original file and not the contents
            3. Removing soft link doesn't affect anything, but when the original file is removed, the link becomes a 'dangling' link that points to nonexistent file
            4. Soft link can link to a directory
            5. Symbolic links can span file systems as they are simply the name of another file.
            6. when creating a dynamic library, we create soft link. so it be thought as pointer to a file.
            7. hard link can be used for backup.


    int lstat(const char *restrict pathname, struct stat *restrict buf );
        The lstat function is similar to stat, but when the named file is a symbolic link, lstat returns information about the symbolic link, not the file referenced by the symbolic link.

    int fstatat(int fd, const char *restrict pathname,struct stat *restrict buf, int flag);
        The fstatat function provides a way to return the file statistics for a pathname relative to an open directory represented by the fd argument. The flag argument controls whether symbolic links are followed. When the AT_SYMLINK_NOFOLLOW flag is set, fstatat will not follow symbolic links, but rather returns information about the link itself. Otherwise, the default is to follow symbolic links, returning information about the file to which the symbolic link points. If the fd argument has the value AT_FDCWD and the pathname argument is a relative pathname. If the pathname argument is an absolute pathname, then the fd argument is ignored. In these two cases, fstatat behaves like either stat or lstat, depending on the value of flag.

    Most files on a UNIX system are either regular files or directories, but there are additional types of files. The types are:
        1. Regular file. The most common type of file, which contains data of some form. There is no distinction to the UNIX kernel whether this data is text or binary. Any interpretation of the contents of a regular file is left to the application processing the file
        2. Directory file. A file that contains the names of other files and pointers to information on these files.
            Any process that has read permission for a directory file can read the contents of the directory, but only the kernel can write directly to a directory file.
        3. Block special file. A type of file providing buffered I/O access in fixed-size units to devices such as disk drives
        4. Character special file. A type of file providing unbuffered I/O access in variable-sized units to devices. All devices on a system are either block special files or character special files.
        5. FIFO. A type of file used for communication between processes. It’s sometimes called a named pipe
        6. Socket. A type of file used for network communication between processes.
            A socket can also be used for non-network communication between processes on a single host.
        7. Symbolic link. A type of file that points to another file.

    The type of a file is encoded in the st_mode member of the stat structure. We can determine the file type with the macros.
        S_ISREG() regular file
        S_ISDIR() directory file
        S_ISCHR() character special file
        S_ISBLK() block special file
        S_ISFIFO() pipe or FIFO
        S_ISLNK() symbolic link
        S_ISSOCK() socket

        /etc/passwd: regular
        /etc: directory
        /dev/log: socket
        /dev/tty: character special
        /dev/sr0: block special
        /dev/cdrom: symbolic link

14)
    The dirent structure defined in the file <dirent.h>
      struct dirent {
            ino_t d_ino;                  /* i-node number */
            char  d_name[NAME_MAX + 1];   /* null-terminated filename */
          }

    When you log into your UNIX system, you provide a username and a password at the login prompt. The login(1) program looks up that username in a database and obtains your registered password. It encrypts the password you supply at login and compares it to the one that is registered. If they are equal, the login(1) program lets you pass in peace. Once you are logged in, however, you become just a number to the UNIX kernel. This user ID number simplifies user and security management for the kernel. In addition to logging in with a user ID, you log in with a group ID.

    To find out what user ID number you are, the id(1) command can be used:
    $ id
    uid=1000(panther2) gid=1000(panther2) groups=1000(panther2),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),108(lpadmin),124(sambashare)
    The id(1) command indicates that the user panther2 is user ID number 100 and is a member of group number 1000. The user and group names are shown in brackets. These were obtained by looking up the user ID and group ID numbers in the password and group file databases, respectively. above informations are stored in inode and can be checked using [ stat <fielname> ]

    Linux is a multi-user system which means that more than one person can interact with the same system at the same time. User creation is handled with the useradd command.

    Groups are collections of zero or more users. A user belongs to a default group, and can also be a member of any of the other groups. The groups command prints the name of groups a user is part of. To view all the groups and members: $cat /etc/group

    groupadd command is used to create a new user group. To add a new user into the group, the group is mentioned using -g option in the command useradd. deluser program removes a user from a group. You can permanently remove a group with the groupdel command.

    All files and directories in Linux have a standard set of access permissions. These access permissions control who can access what files, and provides a fundamental level of security to the files and directories in a system. Linux divides authorization into 2 levels:
        Ownership
        Permission
    Every file and directory on your Unix/Linux system is assigned 3 types of owner:
        User:
            The username of the person who owns the file/directory. By default, the user who creates the file/directory will become its owner.
        Group:
            A user- group can contain multiple users. All users belonging to a group will have the same access permissions to the file.
        Other:
            Any other user who has access to a file. This person has neither created the file, nor he belongs to a usergroup who could own the file. Practically, it means everybody else.

    Permissions: Every file and directory in your UNIX/Linux system has following 3 permissions defined for all the 3 owners. Read, Write, Execute. You can view the permission of the current directory by typing the following command $ ls -l.
        r = read permission
        w = write permission
        x = execute permission
        - = no permission

        r = 4
        w = 2
        x = 1

    The chmod command is used to alter the permissions of a file. Every file is owned by a specific user (or UID) and a specific group (or GID). The chown command can be used to change just the user, or the user and group of a file. The basic format for the chown command is as follows:
    # chown user:group filename

    The st_size member of the stat structure contains the size of the file in bytes. This field is meaningful only for regular files, directories, and symbolic links. For a symbolic link, the file size is the number of bytes in the filename.

15)
    What is a Process? A program is a binary file on a storage medium; by itself, it is a dead object. When you run the program say from shell, it does indeed come alive, and become a process. A process is program that is running.

    To keep track of all these processes, your operating system gives each process a number - PID (Process ID). Processes also have a ppid which is short for parent process id. Process ID 0 is usually the scheduler process and is often known as the swapper. Process ID 1 is usually the init process(sysvinit) or systemd(systemd) and is invoked by the kernel at the end of the bootstrap procedure.

    run [ ps -ef | less ] and check 1 is assigned to systemd and if we use sysvinit then pid 1 is assigned to init. Ususally, it is first process. systemd and sysvinit are init managers and those start a process. systemd is newer and it is being adapted now.

    #include <unistd.h>
    System Call: pid_t getpid(void);
    Returns: process ID of calling process

    pid_t getppid(void);
    Returns: parent process ID of calling process

    Every process has six or more IDs associated with it.
        who we really are:
            - real user ID:The real user ID/group ID is the uid of the user who originally ran the process. These two fields are taken from our entry in the password file when we log in.
            - real group ID: When we execute a program file, the effective user ID of the process is usually the real user ID, and the effective group ID is usually the real group ID. Every file has an owner and a group owner.
    used for file access permission checks
            effective user ID
            effective group ID
    saved by exec functions
            saved set-user-ID
                The saved user ID is the process's original effective user ID. Upon an exec call, the kernel sets the Saved User ID to the effective user ID. This is used to switch back and forth between a privileged to unprivileged state for our process.
            saved set-group-ID
                However, we can also set a special flag in the file’s mode word (st_mode) that says, ‘‘When this file is executed, set the effective user ID of the process to be the owner of the file (st_uid).’’ Similarly, we can set another bit in the file’s mode word that causes the effective group ID to be the group owner of the file (st_gid). These two bits in the file’s mode word are called the set-user-ID bit and the set-group-ID bit. For example, if the owner of the file is the superuser and if the file’s set-user-ID bit is set, then while that program file is running as a process, it has superuser privileges. This happens regardless of the real user ID of the process that executes the file. As an example, the UNIX System program that allows anyone to change his or her password, passwd(1), is a set-user-ID program. This is required so that the program can write the new password to the password file, typically either /etc/passwd or /etc/shadow, files that should be writable only by the superuser.

    uid_t getuid(void);
    Returns: real user ID of calling process

    uid_t geteuid(void);
    Returns: effective user ID of calling process

    gid_t getgid(void);
    Returns: real group ID of calling process

    gid_t getegid(void);
    Returns: effective group ID of calling process

    When a program is executed, the process that does the exec can pass command-line arguments to the new program. Each program is also passed an environment list. Like the argument list, the environment list is an array of character pointers, with each pointer containing the address of a null-terminated C string. The address of the array of pointers is contained in the global variable environ. extern char **environ;

    Benefits of Virtual Memory:
        - freeing applications from having to manage a shared memory space,
        - increased security due to memory isolation,
        - being able to conceptually use more memory than might be physically available, using the technique of paging

    Each process has its own virtual memory. The amount of virtual memory depends on your system's architecture. Each OS handles virtual memory differently, but for most modern operating systems, the virtual memory of a process looks like this:
             address|-------------------| command-line arguments
                    |-------------------| and environment variables
                    |        stack      |
                    |-------------------|
                    |                   |
                    |                   |
                    |                   |
                    |-------------------|
                    |               heap|
                    |-------------------|
                    |uninitialized data | initialized to
                    |               (bss| zero by exec
                    |-------------------|
                    | initialized data  | read from
                    |-------------------| program file
                    |               text| by exec
        low address |-------------------|
                Typical memory arrangement

    High Memory Addresses : Command Line Arguments + Environmental Variables + Stack Growing downwards
    Low Memory Addresses:  Heap Growing Upwards + Executable

    The proc filesystem is a pseudo-filesystem which provides an interface to kernel data structures. It is commonly mounted at `/proc`. Most of it is read-only, but some files allow kernel variables to be changed.
        - /proc/[pid]/mem : This file can be used to access the pages of a process's memory through open(2), read(2), and lseek(2).
        - /proc/[pid]/maps :  A  file containing the currently mapped memory regions and their access permissions.

16)
    There are eight ways for a process to terminate. Normal termination occurs in five ways:
        1. Return from main
        2. Calling exit /* run [ man exit ] for more details, it is library call */
        3. Calling _exit or _Exit /* run [ man exit ] for more details, it is system call */
        4. Return of the last thread from its start routine
        5. Calling pthread_exit from the last thread
    Abnormal termination occurs in three ways
        6. Calling abort
        7. Receipt of a signal
        8. Response of the last thread to a cancellation request

    A call to exit() performs some basic shutdown steps, and then instruct the kernel to terminate the process. The function has no way of returning an error - in fact, it never returns at all. status parameter is used to denote the process's exit status. status & 0377 is returned to the parent. Before terminating the process, the C Library performs the following shutdown steps in order:
        1. Call any functions registered with atexit(), in the reverse order of their registration
        2. Flush all open standard I/O streams
        3. Remove any temporary files created with the tmpfile() function.
    The above operations are performed in user space, so exit() invokes the system call _exit() to let the kernel handle the rest of the termination process. The kernel cleans up the
        allocated memory,
        open files,
        System V Semaphores
        Destroys the process and notifies the parent of the child exit

17)
    An existing process can create a new one by calling the fork function. After a successful fork, execution in both the parent and child process continues at the instruction following the fork. Why does this happen? the job of fork is to make a (pretty much) identical copy of the parent in the child; this includes the hardware context (mentioned earlier), which of course includes the Instruction Pointer (IP) register (sometimes called the Program Counter (PC)) itself! Hence, the child process too will execute the user mode code at the same location as the parent.

    When fork() is executed the entire process memory is duplicated including the buffer. Thus the child process starts with a non-empty output buffer which will be flushed when the program exits. System administrators don't like fork-bombs and may set upper limits on the number of processes each user can have or may revoke login rights because it creates a disturbance in the force for other users' programs.

    #include <unistd.h>
    pid_t fork(void);
    Returns: 0 in child, process ID of child in parent, −1 on error

    The new process created by fork is called the child process. and already existing process is called parent process. This function is called once but returns twice. The only difference in the returns is that the return value in the child is 0, whereas the return value in the parent is the process ID of the new child. The reason the child’s process ID is returned to the parent is that a process can have more than one child, and there is no function that allows a process to obtain the process IDs of its children.

    The reason fork returns 0 to the child is that a process can have only a single parent, and the child can always call getppid to obtain the process ID of its parent (Process ID 0 is reserved for use by the kernel, so it’s not possible for 0 to be the process ID of a child.)

    The fork system call clones the current process to create a new process. It creates a new process (the child process) by duplicating the state of the existing process with a few minor differences. Thus, when a child process is created, the OS will copy the parent's
        text,
        data (three of them),
        library (and other mappings), plus
        the stack segment to the child.
    Hang on though; it does not stop there: There is more, much more, to a process than just its VAS.
        Open files
        Process credentials
        Scheduling information
        Filesystem (VFS) structures
        Paging tables
        Namespaces
        Signal dispositions
        Resource limits
        IPC structures
        Profiling (perf) information
        Security information:
        Thread stacks and TLS
        Hardware context

    The following attributes of the parent process are not inherited by the child process upon forking:
        PID
        PPID
        Locks
        Pending and blocked signals (cleared for child)
        Timers,
        alarms (cleared for child)
        Audit information (CPU/time counters are reset for child)
        Semaphore adjustments made via semop(2)
        Asynchronous IO (AIO) ops and contexts

    The child process does not start from main. Instead it returns from fork() just as the parent process does. In older UNIX systems, the entire address space of the parent process was directly copied (regardless of whether the resource was modified or not). These days, kernel performs copy-on-write, which saves a lot of resources, while being very time efficient.

    Modern implementations don’t perform a complete copy of the parent’s data, stack, and heap, since a fork is often followed by an exec. Instead, a technique called copy-on-write (COW) is used. These regions are shared by the parent and the child and have their protection changed by the kernel to read-only. If either process tries to modify these regions, the kernel then makes a copy of that piece of memory only, typically a ‘‘page’’ in a virtual memory system.

    In general, we never know whether the child starts executing before the parent, or vice versa. The order depends on the scheduling algorithm used by the kernel. If it’s required that the child and parent synchronize their actions, some form of interprocess communication is required.

    When a process terminates, either normally or abnormally, the kernel notifies the parent by sending the SIGCHLD signal to the parent. Because the termination of a child is an  asynchronous event—it can happen at any time while the parent is running — this signal is the asynchronous notification from the kernel to the parent. The parent can choose to ignore this signal, or it can provide a function that is called when the signal occurs: a signal handler. The default action for this signal is to be ignored.

    #include <sys/wait.h>
    pid_t wait(int *statloc);
    pid_t waitpid(pid_t pid, int *statloc, int options);

    a process that calls wait or waitpid can
        - Block, if all of its children are still running
        - Return immediately with the termination status of a child, if a child has terminated and is waiting for its termination status to be fetched
        - Return immediately with an error, if it doesn’t have any child processes
    The differences between these two functions are as follows:
        - The wait function can block the caller until a child process terminates, whereas waitpid has an option that prevents it from blocking
        - If the caller blocks and has multiple children, wait returns when one terminates. We can always tell which child terminated, because the process ID is returned by the function.

    The parent is notified via a signal, SIGCHLD, when the child process finishes but not vice versa.

    Do child processes share open filehandles? Yes! In fact both processes use the same underlying kernel file descriptor. For example if one process rewinds the random access position back to the beginning of the file, then both processes are affected. Both child and parent should close (or fclose) their file descriptors or file handle respectively.

    When a child finishes (or terminates) it still takes up a slot in the kernel process table.  Furthermore, they still contain information about the process that got terminated, such as process id, exit status, etc. (i.e. a skeleton of the original process still remains). Only when the child has been 'waited on' will the slot be available and the remaining information can be accessed by the parent. A long running program could create many zombies by continually creating processes and never wait-ing for them.

    Eventually there would be insufficient space in the kernel process table to create a new processes. Thus fork() would fail and could make the system difficult / impossible to use - for example just logging in requires a new process!

    int system(const char* cmd);
    system() is used to invoke an o.s cmd from c/c++ program. Using system(), we can execute any command that can be run on the terminal.

    The system call will fork, execute the command passed by parameter and the original parent process will wait for this to finish. This also means that system is a blocking call: The parent process can't continue until the process started by system exits. This may or may not be useful.

18)
    In Linux, the act of loading into memory and executing a program image is separate from the act of creating a new system process. One system call loads a binary program into memory, replacing the previous contents of the address space, and begins execution of the new program. This is called executing a new program. Provided by exec family of calls. Act of creating a new processs is called forking, and this functionality is provided by fork() system call.

    There is no single exec function; instead there is a family of exec functions
    Header File: #include <unistd.h>

    int execl(const char *path, const char *arg, ...);
    int execlp(const char *file, const char *arg, ...);
    int execle(const char *path, const char *arg,
                    ..., char * const envp[]);
    int execv(const char *path, char *const argv[]);
    int execvp(const char *file, char *const argv[]);
    int execvpe(const char *file, char *const argv[],
                    char *const envp[]);

    The process ID does not change across an exec, because a new process is not created; exec merely replaces the current process — its text, data, heap, and stack segments — with a brand-new program from disk. The base of each is exec (execute), followed by one or more letters which defines meaning of each call:
        e – An array of pointers to environment variables is explicitly passed to the new process image.
        l – Command-line arguments are passed individually (a list) to the function. You must include NULL after your last
       parameter.:
        p – Uses the PATH environment variable to find the file named in the file argument to be executed.
        v – Command-line arguments are passed to the function as an array (vector) of pointers.

    In Linux, only one member ( execve ) of the exec family is a system call. The rest are wrappers in the C Library around the system call (execve). This was done beacuse
        1. Variadic System Calls would be difficult to implement
        2. Concept of user's path exist in user space

    1. Fire up a shell
    2. In the window, or more precisely, at the shell prompt, type this: $ exec ps

    Yes, the terminal window process is the predecessor here; upon an exec it's overwritten by the successor process ps, which does its work and exits (you probably did not see the output as it disappeared too quickly). ps is the successor process, and, of course, we cannot return to the predecessor (the Terminal window)—ps has literally replaced its VAS. Thus, the Terminal window effectively disappears.

    1. Fire up a shell
    2. In the window, or more precisely, at the shell prompt, run ps followed by bash — yes, we're spawning a subshell here, followed by ps once more.
    $ps
    $bash
    $ps
    notice the PIDs of the original and sub-shell Bash processes

    3. On the sub-shell, exec the ps command; this ps successor process overwrites (or overlays) the process image of the predecessor process—the bash sub-shell. $exec ps
    4. Observe the output: In the exec ps command output, the PID of ps is the PID of the bash subshell process:
    5. Also notice we're back to the original bash shell process PID 3,396 now, as, of course, we cannot return to the predecessor.

    Key points during an exec operation:
        ---> The successor process overwrites (or overlays) the predecessor's virtual address space. In effect, the predecessor's text, data, library, and stack segments are now replaced by that of the successor's. The OS will take care of the size adjustments.
    ---> No new process has been created - the successor runs in the context of the old predecessor. Several predecessor attributes (including but not limited to the PID and open files) thus get auto-inherited by the successor.
    ---> On a successful exec, there is no possibility of returning to the predecessor; it's gone.

19)
    A signal is an event generated by the UNIX and Linux systems in response to some condition, upon receipt of which a process may in turn take some action. Signal can be thought of as software interrupt.

    Who can send signals?
        ----> Kernel to Process
        ----> Process to another Process
        ----> Process to itself
    note: no signal from process to kernel. also no kernel to kernel.

    What happens when the process receives a signal which it is not catching?
        ------>  the process will be terminated immediately
        ------>  a core dump file is created.
        ------>   This file, called core and placed in the current directory
        ------>   is an image of the process that can be useful in debugging

    types of signals in Linux:
        Two types:
        1. Maskable
            Maskable signals or interrupts in Linux are those signals which can be changed or ignored by the user. E.g. ctrl+c , ctrl+\
        2. Non Maskable
            Non-Maskable signals or interrupts are those interrupts which cannot be changed or ignored by the user. For example, Ctrl+Z. E.g. ctrl+z


    Meaning of each signals:
        - SIGHUP          ---->   If a process is being run from terminal and that terminal suddenly goes away then the process receives this signal. “HUP” is short for “hang up” and refers to hanging up the telephone in the days of telephone modems
        - SIGINT          ---->   The process was “interrupted”. This happens when you press Control+C on the controlling terminal.
        - SIGQUIT         ---->   Control+\
        - SIGILL          ---->   Illegal instruction. The program contained some machine code the CPU can't understand.
        - SIGTRAP         ---->   This signal is used mainly from within debuggers and program tracers
        - SIGABRT         ---->   The program called the abort() function. This is an emergency stop
        - SIGBUS          ---->   An attempt was made to access memory incorrectly. This can be caused by alignment errors in memory access etc.
        - SIGFPE          ---->   A floating point exception happened in the program.
        - SIGKILL         ---->   The process was explicitly killed by somebody wielding the kill program.
        - SIGUSR1         ---->   Left for the programmers to do whatever they want
        - SIGSEGV         ---->   An attempt was made to access memory not allocated to the process. This is often caused by reading off the end of arrays etc.
        - SIGUSR2         ---->   Left for the programmers to do whatever they want.
        - SIGPIPE         ---->   If a process is producing output that is being fed into another process that consume it via a pipe (“producer | consumer”) and the consumer dies then the producer is sent this signal.
        - SIGALRM         ---->   A process can request a “wake up call” from the operating system at some time in the future by calling the alarm() function. When that time comes round the wake up call consists of this signal.
        - SIGTERM         ---->   The process was explicitly killed by somebody wielding the kill program.
        - SIGSTKFLT       ---->   Stack fault on coprocessor
        - SIGCHLD         ---->   The process had previously created one or more child processes with the fork() function. One or more of these processes has since died.
        - SIGCONT         ---->   (To be read in conjunction with SIGSTOP.) If a process has been paused by sending it SIGSTOP then sending SIGCONT to the process wakes it up again (“continues” it).
        - SIGSTOP         ---->   (To be read in conjunction with SIGCONT.)If a process is sent SIGSTOP it is paused by the operating system. All its state is preserved ready for it to be restarted (by SIGCONT) but it doesn't get any more CPU cycles until then.
        - SIGTSTP         ---->   Essentially the same as SIGSTOP. This is the signal sent when the user hits Control+Z on the terminal. (SIGTSTP is short for “terminal stop”) The only difference between SIGTSTP and SIGSTOP is that pausing is only the default action for SIGTSTP but is the required action for SIGSTOP. The process can opt to handle SIGTSTP differently but gets no choice regarding SIGSTOP
        - SIGTTIN         ---->   The operating system sends this signal to a backgrounded process when it tries to read input from its terminal. The typical response is to pause (as per SIGSTOP and SIFTSTP) and wait for the SIGCONT that arrives when the process is brought back to the foreground
        - SIGTTOU         ---->   The operating system sends this signal to a backgrounded process when it tries to write output to its terminal. The typical response is as per SIGTTIN.
        - SIGURG          ---->   The operating system sends this signal to a process using a network connection when “urgent” out of band data is sent to it.
        - SIGXCPU         ---->   The operating system sends this signal to a process that has exceeded its CPU limit. You can cancel any CPU limit with the shell command “ulimit -t unlimited” prior to running make though it is more likely that something has gone wrong if you reach the CPU limit in make.
        - SIGXFSZ         ----->  The operating system sends this signal to a process that has tried to create a file above the file size limit. You can cancel any file size limit with the shell command “ulimit -f unlimited” prior to running make though it is more likely that something has gone wrong if you reach the file size limit in make.
        - SIGVTALRM       ----->  This is very similar to SIGALRM, but while SIGALRM is sent after a certain amount of real time has passed, SIGVTALRM is sent after a certain amount of time has been spent running the process.
        - SIGPROF         ----->  This is also very similar to SIGALRM and SIGVTALRM, but while SIGALRM is sent after a certain amount of real time has passed, SIGPROF is sent after a certain amount of time has been spent running the process and running system code on behalf of the process.
        - SIGWINCH        ----->  (Mostly unused these days.) A process used to be sent this signal when one of its windows was resized
        - SIGIO           ----->  (Also known as SIGPOLL.) A process can arrange to have this signal sent to it when there is some input ready for it to process or an output channel     has become ready for writing.
        - SIGPWR          ----->  A signal sent to processes by a power management service to indicate that power has switched to a short term emergency power supply. The process (especially long-running daemons) may care to shut down cleanlt before the emergency power fails
        - SIGSYS          ----->  Unused

    Sending signals from Keyboard:
        ----->  When you press CTRL+C key, a SIGINT  is sent which default action is to terminate the process
        -----> When you press CTRL+\ key, a SIGQUIT is sent which default action is to terminate the process dumping core
        -----> When you press CTRL+Z key, a SIGSTOP signal is sent that suspends the program

    Other common method is to use the kill command.
        kill -signal pid
        killall -signal binary
    The difference between kill and killall is that kill only sends signals to process identified by their pid, killall sends the signal to all process of a given name.

    With Signals, a process can asynchronously receive information about certain events or condition. A process can trap or subscribe to a signal; when this occurs, the process will asynchronously be notified of the fact by the OS, and will then run the code of a function in response: a signal handler.

    Examples:
        1. The developer wants to perform a common task: set up a timer and have it expire in, say, 1.5 seconds from now. How will the OS inform the process that the timer has expired?
        2. A process has an inadvertent defect (a bug); it makes an invalid memory access. subsystem (well, technically, the MMU and the OS) determines it must be killed. How exactly will it be killed?
        3. Linux's asynchronous IO (AIO) framework, and many other such scenarios.

    In C, send a signal to the child using kill POSIX call, Signals are also a key means for inter-process communication. One process can send a signal to another indicating that an action should be taken. To send a signal to a particular process, we use the kill() system call.
        int kill(pid_t pid, int signum);
        kill(child, SIGUSR1); // Send a user-defined signal

    How to handle Signals? The primary system call for signal handling is signal()

    int main()
    {
            signal(SIGPWR, powerFailureHandler);
            .......
    }
    void powerFailureHandler(int signum)
    {
            //Saves states to restore later
            .......
    }

    The first line in main() establishes a handler for the SIGPWR signals. Arguments:
    int signal(int signum, void (*handler)(int))
        first argument: signal number, such as SIGSTOP or SIGINT
        second argument: a function pointer type which points to the signal handler.

    the second argument to signal() is a function pointer, a reference to a function to call. This tells the operating system that whenever this signal is sent to this process, run this function as the signal handler. Also, the execution of the signal handler is asynchronous, which means the current state of the program will be paused while the signal handler executes, and then execution will resume from the pause point, much like context switching.

    What happens when forking? The child process inherits a copy of the parent's signal dispositions. In other words, if you have installed a SIGINT handler before forking, then the child process will also call the handler if a SIGINT is delivered to the child.

    The two signals that can never be ignored or handled are: SIGKILL and SIGSTOP.

20)
    The default action for things like SIGSEGV is to terminate your process but as you've installed a handler for it, it'll call your handler overriding the default behavior. But the problem is segfaulting instruction may be retried after your handler finishes and if you haven't taken measures to fix the first seg fault, the retried instruction will again fault and it goes on and on. So, in this program when we execute, it continously goes into sighandler.

    Can multiple signals be queued? No - however it is possible to have signals that are in a pending state. If a signal is pending, it means it has not yet been delivered to the process. The most common reason for a signal to be pending is that the process (or thread) has currently blocked that particular signal. If a particular signal, e.g. SIGINT, is pending then it is not possible to queue up the same signal again. It is possible to have more than one signal of a different type in a pending state. For example SIGINT and SIGTERM signals may be pending (i.e. not yet delivered to the target process).

    A SIGALRM signal is delivered by the Operating System via a request from the user occuring after some amount of time. Alarm can be set continually, but only one alarm is allowed per process. Subsequent calls to alarm() will reset the previous alarm. Suppose, now, that we want to write a program that will continually alarm every 1 second, we would need to reset the alarm once the signal is delivered. The natural place to do that is in the signal handler

    Blocking a signal means telling the operating system to hold it and deliver it later when it is unblocked. Between the time when it is generated and when it is delivered a signal is said to be pending. Generally, a program does not block signals indefinitely - it might as well ignore them by setting their actions to SIG_IGN.

    Is Blocking a signal similar to Ignoring a signal ? No, blocking a signal is different from ignoring a signal. When a process blocks a signal, the operating system does not deliver the signal until the process unblocks the signal. A process blocks a signal by modifying its signal mask with sigprocmask. But when a process ignores a signal, the signal is delivered and the process handles it by throwing it away.

    Temporary blocking of signals with sigprocmask gives you a way to prevent interrupts during critical parts of your code. If signals arrive in that part of the program, they are delivered later, after you unblock them. All signal blocking functions use a data structure called a signal set to specify what signals are affected. Thus, every activity involves two stages:
        1. creating the signal set, and
        2. then passing it as an argument to a library function.

    The collection of signals that are currently blocked is called the signal mask. Each process has its own signal mask. When you create a new process, it inherits its parent's mask. You can block or unblock signals with total flexibility by modifying the signal mask.

    What happens during fork? The child process inherits a copy of the parent process's signal disposition and a copy of the parent's signal mask. For example if SIGINT is blocked in the parent it will be blocked in the child too. For example if the parent installed a handler (call-back function) for SIG-INT then the child will also perform the same behavior. Pending signals however are not inherited by the child.

    What happens during exec? Both the signal mask and the signal disposition carries over to the exec-ed program. Pending signals are preserved as well. Signal handlers are reset, because the original handler code has disappeared along with the old process.

    What happens when a signal is received while already in a signal handler? the signal is delivered after the signal handler has finished.

21)
    What is strace? strace stands for system call tracer. It is a debugging tool that
        monitors the system calls used by a program and
        all the signals it receives.
    System calls are used by userspace applications when they need to do something that requires the kernel. strace may provide you with valuable information for many problem cases, for example: which config files really were read, which was the last file or shared library read before your program crashed, and so on

    What it does?
        ----> Learn which system calls a program make
        ----> Find those system calls that fail together with error code
        ----> Find which files a program opens
        ----> Find out what syscalls a running program is making, for example to see if it is struck in a loop

    Using strace is quite simple. There are two ways to let strace monitor a program.
        Method 1:
            $ strace program_name
            Ex: $ strace ls
            strace emits its entire output to stderr
        Method 2:
            If we want to monitor a process which is currently running we can attach to the process using –p option.
                $ strace –p <pid-of-the-application>

    strace is very useful while debugging crashes.  Some scenarios where strace can be helpful are –
        ----> When you don't have source code
        ----> program behaving poorly
        ----> nothing in the log files
        ----> nothing in stdout
        ----> no ports responding
        ----> don't want to open gdb
        ----> Debugging why an installation crashes on a machine.
        ----> Debugging random crashes that are most probably due to the program running out of memory or due to it requesting an arbitrarily large chunk of memory.
        ----> Finding out how the program interacts with the file system.
        ----> Debugging crashes reproducibly only on one machine.
        ----> Debugging crashes in unfamilar code or in cases when sources are unavailable.

    Child Processes: Sometimes the process you trace doesn't do the real work itself, but delegates it to child processes that it creates. If that's the case, you may want to pass -f to make strace "follow forks" and trace child processes, too, as soon as they're made. '-ff' - follows forks with separate output files per-fork

    Attaching strace to a running process: strace can also be attached to a running process and can be used to record its system calls. To do this, we must know the PID of the process which we want to debug. We can get this PID using the ps command.

    Sometimes the full syscall trace is too much. Using –e option we can also specify which system calls to be traced. To trace only open() and close() system calls use the following command: $ strace –e trace=’open,close’ <program-name>

    The -i option displays the instruction pointer at the time of each system call made by the program.

    ltrace is a debugging utility in Linux, used to display the calls a userspace application makes to shared libraries. Its name itself comes from library-call tracing. This tool is very useful for debugging user-space applications to determine which library call is failing.

    ltrace ./executable <parameters>

    ltrace(1) also allows you to selectively trace library calls when executed with the “-e” option and a set of calls to trace: $ ltrace -e malloc /bin/cat

    If you need to view the library calls from a live process, you can use ltrace(1)’s “-p” option: $ ltrace -p 2644. The parameter -c outputs the number and duration of the library calls that have occurred. $ ltrace -c ls /

22)
