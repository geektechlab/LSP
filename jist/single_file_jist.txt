1)
    list of commands:
    - sudo -- super user do. If you prefix “sudo” with any command, it will run that command with elevated privileges which allows a user with proper permissions to execute a command as superuser.
    - ls
    - cd: Change directory. Allow the user to change between file directories.
            cd --> Will change to the home directory
            cd - --> Will switch to the old directory
            cd ~ --> Will move to the home directory
                $cd ~/Linux_System_Prog
    - pwd: Will print the current working directory
    - touch: Allows user to make files from the command line Interface
    - rm: This command is used to remove files
    - mkdir: Allows user to create a new directory.
    - rmdir: Allows user to remove a directory
    - mv: Allows user to move file from one place to another
    - cp: $cp file1 file2
    - clear: clear command will take the user back to the start prompt of directory you are currently operating in
    - man: Use to show the manual of the command passed
            $ man man
            man has various sections, same command can be executable program, shell command, system call, library call, etc., so to differentiate we can specify. man <number> <command>. e.g., man 2 man. Number can be found using [man man].
    - find: $find <path> -name 'filename'. $find / -name "*conf" -mtime 7.
    - echo: It prints the strings that are passed as arguments to the standard output.
            To append to a file
            $ echo "Test Page" >> testpage
    - cat: cat stands for concatenate
            Display the contents of the file. $cat /etc/passwd
            Create a file with cat command. cat > file.txt. Will create a file 'file.txt' and allows user to type the content on the console.
    - more: view contents of text file one page at a time.
    - less: linux utility which can be used to read contents of text file one page(one screen) per time.
    - head: outputs the first part (the head) of a file or files. head, by default, prints the first 10 lines.
    - tail: prints the last few number of lines (10 lines by default) of a certain file, then terminates.
    - pipe | : Linux systems allow stdout of a command to be connected to stdin of another command. You can make it do so by using the pipe character ‘|’. command_1 | command_2 | command_3 | .... | command_N. $cat sample2.txt | head -7 | tail -5.
    - tee : reads from the standard input and writes to both standard output and one or more files at the same time. $df -h | tee disk_usage.txt
    - ps : Provides information about currently running processes. daemon can be created by &. generally ssh runs as daemon. [./hello &] will run hello executable as daemon. We can kill by [ kill %<number> ] given by jobs command.
    - grep: It searches for the given string in the specified file.
    - wc: word count. [ wc filename.txt ] will show number of lines, words and bytes
    - top : displays the top processes in the system ( by default sorted by cpu usage ).
    - df : Displays the file system disk space usage.
    - uname : displays important system information:Kernel name, Host name, Kernel release number, Processor type, etc.,
    - date : Set the system date.
    - ping : Check network connectivity
    - which : Used to locate the executable file associated with the given command by searching it in the path environment variable.
    - whoami : whoami command print the name of current user
    - lsof : lsof mean List of all open files.
    - history
    - time: Find time taken by a command/program on Linux Shell
            real: Total end to end time taken by program/command
            user: Time taken in user mode.
            sys: Time taken in kernel mode

2)
    - tree -L 1 /. show only the 1st level of the directory tree starting at root (/).

    In Linux however, the root of the filesystem doesn’t correspond with a physical device or location, it’s a logical location of simply “/”.
        / (Root) : Every single file and directory starts from the root directory
        /boot :  Contains files required for starting your system. Boot loader files, e.g., kernels, initrd. config-* - contains kernel configuration settings. e.g. if we want to know if HID is enable, we can run [ cat /boot/config-`uname -r`-generic | grep HIDRAW.
                    - initrd.img-* - initrd - initial ram disk is loaded by the kernel at boot time, it loads temporary file system into RAM at the time of booting, before actually mounting actual file system
                    - vmlinuz-* - virtual memory Linux kernel zipped. vmlinuz is a compressed Linux Kernel image which is used at the time of booting Linux operating system. vmlinuz used by Intel. Arm uses uimage if we use u-boot. x86, grub uses vmlinuz. When grub starts, it uncompresses this image and starts loading.
                    - System.map-* - the System.map file is a symbol table used by the kernel. A symbol table is a look-up between symbol names ( variable or function ) and their addresses in memory. It is useful when kernel panics it will print various address, then we can use directly this system.map file to convert those addresses into function or variable names.
                    - grub/grub.conf - This file is used for boot loader grub to load grub related configuration. If we want to modify any configuration in grub bootloader, we use this.
        - /bin folder: bin stands for binary which means an executable file. This folder contains basic commands such as cat, chmod, chgrp, chown, date, dir, dd, df, ln, mv, echo.
        - /sbin: stands for system binaries or super user binaries. It contains commands that need to be available at the very beginning of the OS initialization and at the shutdown end too. Contains commands required for changing system properties or system level settings such as disk management, network management etc. e.g. fsck, root, init, ifconfig
        - /usr is generally for user / administrator added binaries.
                /usr/bin: commands which are not installed locally should be placed in this directory. Eg. vi, atq, bc, awk, cal, cmp, dig, diff, du, env, find, free, ftp, gcc, groups, id, info iostat, last, lsof, md5sum, nmap, rar, seq, tail, top.
        - /usr/sbin: contains non-vital system utilities that are used after booting (i.e., starting the system) by the system administrator. Eg.  adduser, chroot, groupadd, grub related commands, tcpdump. Also contains some daemons, which are programs that run silently in the background: Eg. bluetoothd, dropbear
        - /usr/local is a place where files built by the system administrator are placed
            - /usr/local/bin: Binaries for programs local to the site.
            - /usr/local/sbin: Locally installed programs for system administration
        - /dev: Linux/Unix treats hardware devices too as files. All hardware files are present in /dev(Device ) folder. e.g., /dev/null. Many of these are generated at boot time or even on the fly.
                character devices example:
                    /dev/lp0 represents the first printer port
                    /dev/ttyS0 represents the first serial port
                Block devices:
                    /dev/hd* represents hard disk drives.
                    /dev/sd* represents SCSI devices
        - /etc: Contains system-wide configuration files. Contains configuration files required by all programs. This also contains startup and shutdown shell scripts used to start/stop individual programs.
            Example: /etc/resolv.conf, /etc/logrotate.conf. [ cat /etc/passwd ]
            /etc/hostname -- Contains the hostname of your machine
            /etc/modules -- List of modules to be loaded at startup.
            /etc/hosts -- The hosts file is used to map hostname to IP Address
            /etc/fstab -- this file automatically mounts filesystems that are spread across multiple drives or separate partitions. This file is checked when the system boots and filesystems are mounted. During boot, kernel reads this file and mounts all filesystem listed here. e.g. [ cat /etc/fstab ] and the verify same UUID using [ blkid /dev/<filesystem> ]
            /etc/passwd - user details
        - /home: for all users to store their personal files. For example, if your user name is bob, you have a home folder located at /home/bob. Each user only has write access to their own home folder and must obtain elevated permissions (become the root user) to modify other files on the system. [ echo $HOME ] gives path of home folder for a user. If we become root by su or sudo -s command the  above command will display root home folder.
        - /root: Home directory of root user
        - /lib: Libraries essential for the binaries in /bin/ and /sbin/. /lib/modules -- All loadable kernel modules are stored in this directory. /lib<qual> (lib32, lib64 etc): 32bit, 64 bit libs of the same name. A 64-bit system may have compatibility for 32-bit binary.
        -/media: media directory is where external storage will be automatically mounted when you plug it in and try to access it. For example, when you insert a CD into your Linux system, a directory will automatically be created inside the /media directory.
        - /mnt: A directory for temporarily mounted filesystems. For example, if youre mounting a Windows partition to perform some file recovery operations, you might mount it at /mnt/windows. Eg. iso files: mount -t iso9660 -o loop path/to/image.iso /mnt/
        - /tmp: Temporary files. Often not preserved between system reboots, and may be severely size restricted.
        - /run: /run is another new directory. System processes use it to store temporary data for their own nefarious reasons. Mostly contains pid related information.
        - /srv: The /srv directory contains data for servers ( such as Apache, FTP, web server etc. ). If you are running a web server from your Linux box, your HTML files for your sites would go into /srv/http (or /srv/www). If you were running an FTP server, your files would go into /srv/ftp.
        - var: /var contains variable data files. This includes spool directories and files, administrative and logging data, and transient and temporary files. /var/log contains log files for differenctt applications. dmesg is also located here. /var/mail contains users emails. /var/run holds a lot status and parameter information of actively running process daemons.
        - opt: third party installers
        - lost+found: fsck command is used to recover these files. Any file to be recovered is kept in this folder
        - Proc: These are virtual file systems most used in device drivers. It means that files are not present in hard disk or in any media storage. these are stored in RAM and whenever we start system, files will be created in RAM. e.g. if we do [ ls -l proc/cmdline ], size will show as 0. but [ cat proc/cmdline ] will give print the content. Since it has content, it should have some size. But since it is not stored in hard dsik/storage/memory, ls shows 0 size. difference between virtual file and actual file:
                virtual file has 0 size
                actual file has some size
            proc contains special files that represent system and process information. quite a lot of system utilities are simply calls to files in this directory.
                'lsmod' is the same as 'cat /proc/modules'. We can verify it by [ strace lsmod | grep modules ]
                'lspci' is a synonym for 'cat /proc/pci'. We can verify it by [ strace lspci ] tahat it uses sys filesystem.
                /proc/meminfo contains a bunch of information about your system's memory
                /proc/uptime uptime information (in seconds).
                /proc/partitions detailed info about partitions available to the system.
                /proc/cmdline kernel command line information.
            The /proc filesystem maps mostly to the process table. It also raised the issue that /proc was SUPPOSED to be for the process table. So they added another instance, and named it sys aimed to hold system information.
        - sys: sysfs is used by programs such as udev to access device and device driver information. To get the a network card's MAC address. cat /sys/class/net/eth0/address.
    All process related informations are present in proc filesystem. [ ls /proc ]. Whereas, all hardware related informations are present in sys filesystem. [ ls /sys ]. Whenever we create a new module, new folder will get created in /sys/module directory. Whenever we add a new device, new folder will get created in /sys/dev or /sys/bus directory.

3)
    GCC Compilation Process:For example, a "gcc -o hello hello.c" is carried out as follows:
        1. Pre-processing:
            joining continued lines (lines ending with a \), Removal of Comments, Expansion of Macros, Expansion of the included files. The output of this step is a "pure" C file without pre-processor directives.
        2. Compilation:
            Check C program for syntax errors. Translate the file into intermediate code i.e. in assembly language. Optionally optimize the translated code for better performance. Removing unused variables and subroutines.
        3. Assembly:
            During this stage, an assembler is used to translate the assembly instructions to object code. The output consists of actual instructions to be run by the target processor. The contents of this file is in a binary format and can be inspected using hexdump or od by running either one of the following commands:
                $hexdump hello.o
                $od -c hello.o
            At this phase, only existing code is converted into machine language, the function calls like printf() are not resolved. The object code generated in the assembly stage is composed of machine instructions that the processor understands but some pieces of the program are out of order or missing.
        4. Linker:
            To produce an executable program, the existing pieces have to be rearranged and the missing ones filled in. This process is called linking. The result of this stage is the final executable program. [ file hello ] will give info about actual executable. linker will combine all files' .data .txt etc sections in one executable file as combined sections. An object and executable come in several formats:
                - ELF (Executable and Linking Format) is used on Linux. ELF is format used by Linux to store object, executable, shared library and kernel object files.
                - COFF (Common Object-File Format) is used on Windows systems.


    ldd tool will print the shared libraries required by each program:
        $ldd main
            linux-vdso.so.1 =>  (0x00007ffd241f8000)
            libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007fd939b4c000)
            /lib64/ld-linux-x86-64.so.2 (0x000055ab46461000)
    The above output indicates that the main executable depends on three libraries. The first library is required for making system calls. The second library is C Library. The third shared library is the one which loads all the other shared libraries required by the executable.

    Extracting Information from .o and executable binary files: [ $readelf --symbols hello.o ] will show us symbols in the object file. objdump can also be used. [ objdump -D hello.o ] dissassembles the file.

    Linux generated executable will not work on Windows even if machine architecture is same. Because, Linux executable file format is ELF but Windows executable file format is COFF.

    Instruction set Architecture provides the software below information:
        What instructions are available?
        How many and what kind of registers are available?
        Memory: How to access contents
        Software compiled for one ISA will not run on hardware with a different ISA

    Application Binary Interface (ABI): ABI = ISA + More.
        ABI Handles the following:
            Calling Conventions
            How function arguments are passed
            How function return values are retrieved. for example, whether all parameters are passed on the stack or some are passed in registers
            which registers are used for which function parameters
            whether the first function parameter passed on the stack is pushed first or last onto the stack

4-5)
    __attribute__((constructor)) syntax : This particular GCC syntax, when used with a function, executes the same function at the startup of the program, i.e before main() function.
    __attribute__((destructor)) syntax : This particular GCC syntax, when used with a function, executes the same function just before the program terminates through _exit, i.e after main() function.

    Linux Library Types:
        1. Static libraries (.a): Library of object code which is linked with, and becomes part of the application. Static linking is the process of copying all library modules used in the program into the final executable image. This is performed by the linker and it is done as the last step of the compilation process. The linker combines library routines with the program code in order to resolve external references, and to generate an executable image suitable for loading into memory.
                $ gcc hello.c -o hello --static
                run [ ldd ./statichello ] and will give you a output that it is not a dynamic executable.
                [ size statichello ] will give different section sizes. compared to dynamic library, size is huge.
                [ strace statichello ] will list all system calls made and those are less compared to dynamic library.
            Advantages:
                - Faster than shared libraries because a set of commonly used object files is put into a single library executable file.
                - Once everything is bundled into your application, you don’t have to worry that the client will have the right library (and version) available on their system.
            Disadvantages:
                - Executable size is larger
                - If any changes have to be made to the static library (any bug in the static library), it has to be recompiled and relinked back to the application
            When to use static libraries:
                1. When  you aren't sure whether the correct version of a library will be available at runtime
                2. You were testing a new version of a library that you don't yet want to install as shared.
        2. Dynamically linked shared object libraries (.so): There is only one form of this library but it can be used in two ways. Assembler output is obj files. Linker joins object files into one executable. Loader brings executable into memory and starts execution. When using a static linking, the linker finds the bits that the program modules need, and physically copies them into the executable output file that it generates. For dynamic linking, it doesn't copy instead it leaves a note in the executable saying `when this program is run, it will first have to load this library'. Dynamic linking can occur when executable is first loaded and run (load‐time linking). Dynamic linking can also occur after program has begun (run‐time linking).
                    Advantages of Dynamic Linking:
                        - Dynamic libraries provide a means to use code that can be loaded anywhere in the memory. Dynamic library has relocatable address. Once loaded, the library code can be used by any number of programs. This way the size of programs using dynamic library can be kept low as a lot of code is kept common in form of a shared library
                    run [ ldd dynamichello ] and it will give list of libraries dependent on
                    [ strace dynamichello ] will list all system calls made and those are large.
            1. Dynamically linked at run time. The libraries must be available during compile/link phase. The shared objects are not included into the executable component but are tied to the execution.
            2. Dynamically loaded/unloaded and linked during execution. Using the dynamic linking loader system functions.
        How to create the dynamic library:
            1: Create object files using the below command
                $ gcc -fPIC -c *.c
                the -fPIC flag stands for Position Independent Code, a characteristic required by shared libraries
            2: Create the library
                $ gcc -shared -Wl,-soname,libarith.so -o libarith.so *.o
                The -shared key tells the compiler to produce a shared object which can then be linked with other objects to form an executable.

    nm lists symbols ( variables and functions ) from object files.

6-7)
https://github.com/prnjl99/Bare_metal_embedded_development/blob/main/build_scripts/gdb_cmd

8)
    A “core dump” is a snapshot of memory at the instant the program crashed, typically saved in a file called “core”. The core contains the memory contents of the process at the point of the seg-fault including its:
        code segment, data segment, stack segment and heap segment.
    Core dumps allow a user to save a crash for later or off-site analysis, or comparison with other crashes. if we run [ gcc source_code.c -o source_code -g ] and then run [ ./source_code ], then it will print segmentation fault ( core dumped ).

    Valgrind is a debugging tool & is a wrapper around various tools for debugging and profiling. Best tool out of these is MemCheck that is used to find out memory leaks etc.
        $valgrind --tool=memcheck --leak-check=yes  ./1
    Catches common memory bugs (UB) on dynamically allocated memory regions
        Using Uninitialized Variables
        Out-of-bounds memory access(read/write underflow/overflow bugs)
        Use-after-free/use after return(out of scope) bugs
        Double free
        Leakage

9)
    Electric Fence helps you detect overruns the boundaries of a malloc()memory allocation &  software that touches a memory allocation that has been released by free(). Electric Fence replaces the C library's normal malloc() function with a version that allocates the requested memory and (usually) allocates a section of memory immediately after this, which the process is not allowed to access! Electric Fence creates a virtual fence around each allocated buffer in a way that any illegal memory access results in a segmentation fault.

    Standard functions can be divided in two main categories :-
        1. Library function calls.
            The functions which are a part of standard C library are known as Library functions. E.g. strcmp(), strlen()
        2. System function calls.
            The functions which change the execution mode of the program from user mode to kernel mode are known as system calls. E.g. socket(), open(), read() , write()
    A library function is linked to the user program and executes in user space but a system call is not linked to a user program and executes in kernel space. how to find if given given function is library call or system call ? if we do [ man printf ] and we see 1, it means it is executable. we can run [ man man ] to find section numbers and what they corresponds to. We can see 2 is for system call and 3 is for library calls.

10)
    File Descriptors: A process may have several open files which it may be reading from and writing to. Each process has its own array to keep track of:
        - The file opened.
        - The files status (whether open for reading or writing: the file status flags )
        - The current offset within the file

    When a file is opened or created by a process the kernel assigns a position in the above array called the file descriptor. To the kernel, all open files are referred to by file descriptors. A file descriptor is a non-negative integer. When we open an existing file or create a new file, the kernel returns a file descriptor to the process. When we want to read or write a file, we identify the file with the file descriptor that was returned by open or creat as an argument to either read or write. By convention, UNIX System shells associate:
        STDIN_FILENO: file descriptor 0 with the standard input of a process,
        STDOUT_FILENO: file descriptor 1 with the standard output, and
        STDERR_FILENO: file descriptor 2 with the standard error.

    stdout is fully buffered and stderr is not buffered.

    fopen vs open in C:
        fopen
            1) fopen is a library function while open is a system call.
            2) fopen provides buffered IO which is faster compare to open which is non buffered.
            3) fopen is portable while open not portable (because open is environment ( platform - linux/windows etc. ) specific).
            4) fopen returns a pointer to a FILE structure(FILE *); open returns an integer that identifies the file.
            5) A FILE * gives you the ability to use fscanf and other stdio functions.
        open
            A file is opened or created by calling either the open function or the openat function
                #include <fcntl.h>
                int open(const char *path, int oflag, ... /* mode_t mode */ );
                int openat(int fd, const char *path, int oflag, ... /* mode_t mode */ );

    diff btween open and openat is openat takes file descriptor/at cwd.

11-12)
    int creat(const char *path, mode_t mode);
        A better way is to use the open function, as in
        open(path, O_RDWR | O_CREAT | O_TRUNC, mode);

    An open file is closed by calling the close function.
        #include <unistd.h>
        int close(int fd);
        When a process terminates, all of its open files are closed automatically by the kernel. if we use buffered I/O then data will get lost if close is not used after opening. Unbuffered I/O it may be okay.

    Data is written to an open file with the write function.
        #include <unistd.h>
        ssize_t write(int fd, const void *buf, size_t nbytes);

    Data is read from an open file with the read function.
        #include <unistd.h>
        ssize_t read(int fd, void *buf, size_t nbytes);

    Every open file has an associated ‘‘current file offset,’’ normally a non-negative integer that measures the number of bytes from the beginning of the file. Read and write operations normally start at the current file offset and cause the offset to be incremented by the number of bytes read or written. By default, this offset is initialized to 0 when a file is opened, unless the O_APPEND option is specified. An open file’s offset can be set explicitly by calling lseek.
        #include <unistd.h>
        off_t lseek(int fd, off_t offset, int whence);

    The dup system call duplicates an existing file descriptor, returning a new one that refers to the same underlying I/O object. Dup allows shells to implement commands like this:
        ls existing-file non-existing-file > tmp1  2>&1
    The 2>&1 tells the shell to give the command a file descriptor 2 that is a duplicate of descriptor 1. (i.e stderr & stdout point to same fd). Now the error message for calling ls on non-existing file and the correct output of ls on existing file show up in tmp1 file.

    An existing file descriptor is duplicated by either of the following functions
        #include <unistd.h>
        int dup(int fd);
        int dup2(int fd, int fd2);
    The new file descriptor returned by dup is guaranteed to be the lowest-numbered available file descriptor. With dup2, we can specify the value of the new descriptor of our choice with the fd2 argument.

13)
    Inodes: In Linux everything is treated as a file. (even the hardware devices). The keyboard, mouse, printers, monitor, hard disk, processes, even the directories are treated as files in Linux. Set aside the regular data, there are some other data about these files, such as their size, ownership, permissions, timestamp etc. This meta-data about a file is managed with a data structure known as an inode (index node).

    For example, the inode contains
        a list of all the blocks in which a file is stored
        the owner information for that file,
        permissions
        and all other attributes that are set for the file.

    In a sense, you could say that a file really is the inode, and names are attached to these inodes to make it easier for humans to work with them. An inode is a data structure on a traditional Unix-style file system such as ext3 or ext4. Linux extended filesystems such as ext2 or ext3 maintain an array of these inodes: the inode table. This table contains list of all files in that filesystem. The individual inodes in inode table have a unique number (unique to that filesystem), the inode number. an inode stores:
        File type: regular file, directory, pipe etc.
        Permissions to that file: read, write, execute
        Link count: The number of hard link relative to an inode
        User ID: owner of file
        Group ID: group owner
        Size of file: or major/minor number in case of some special files
        Time stamp: access time, modification time and (inode) change time
        Attributes: immutable' for example
        Access control list: permissions for special users/groups
        Link to location of file
        Other metadata about the file

    Note that inode does not store name of the file but its content only. You can display the inode data on a file or directory by using stat command. You need to indicate the name of the file. we can run [ man stat ]. stat can takefile and folder both as input.

    the name of the file is stored within the directories' information structure. directories are special files that are used to create and hold access paths to the files in the file system. A directory file is a list of directory entries, each one containing the following information:
        inode - The inode for this directory entry. This is an index into the array of inodes held in the Inode Table of the Block Group.
        name length - The length of this directory entry in bytes,
        name - The name of this directory entry.
    The first two entries for every directory are always the standard . and .. entries meaning "this directory" and "the parent directory" respectively.

    #include <sys/stat.h>
    int stat(const char *restrict pathname, struct stat *restrict buf );
    Given a pathname, the stat function returns a structure of information about the named file
    struct stat {
        mode_t st_mode; /* file type & mode (permissions) */
        ino_t st_ino; /* i-node number (serial number) */
        dev_t st_dev; /* device number (file system) */
        dev_t st_rdev; /* device number for special files */
        nlink_t st_nlink; /* number of links */
        uid_t st_uid; /* user ID of owner */
        gid_t st_gid; /* group ID of owner */
        off_t st_size; /* size in bytes, for regular files */
        struct timespec st_atim; /* time of last access */
        struct timespec st_mtim; /* time of last modification */
        struct timespec st_ctim; /* time of last file status change */
        blksize_t st_blksize; /* best I/O block size */
        blkcnt_t st_blocks; /* number of disk blocks allocated */
    };

    The biggest user of the stat functions is probably the ls -l command, to learn all the information about a file. we can verify it by running [ strace ls -l ]. The fstat function obtains information about the file that is already open on the descriptor fd.

    A link in Linux is a pointer to a file. Creating links is a kind of shortcuts to access a file. Links allow more than one file name to refer to the same file, elsewhere. Two types of links :
        1. Soft Link or Symbolic links
        2. Hard Links
        3. Nothing

    Hard Link: The basic command structure for creating a hard link is:
        $ln file.txt hard_file.txt
        SOURCE is the original file. LINK is the new file you will create that will point to the original source.
        Important Points:
            1. Hard links will have the same inode number. We can verify it by checking inode values by [ stat <filename> ]. Also check incremented link count. Unix files consist of two parts: the data part and the filename part. The data part is associated with something called an 'inode'. The inode carries the map of where the data is, the file permissions, etc. for the data.
                                                .---------------> ! data ! ! data ! etc
                                               /                 +------+ !------+
                        ! permbits, etc ! data addresses !
                        +------------inode---------------+

                    The filename part carries a name and an associated inode number.

                                        .--------------> ! permbits, etc ! addresses !
                                        /                 +---------inode-------------+
                        ! filename ! inode # !
                        +--------------------+

                    More than one filename can reference the same inode number; these files are said to be 'hard linked' together.

                    ! filename ! inode # !
                    +--------------------+
                                        \
                                         >--------------> ! permbits, etc ! addresses !
                                        /                 +---------inode-------------+
                        ! othername ! inode # !
                        +---------------------+
            so modifying one will affect other. When deleting files, the data part isn't disposed of until all the filename parts have been deleted. There's a count in the inode that indicates how many filenames point to this file, and that count is decremented by 1 each time one of those filenames is deleted. When the count makes it to zero, the inode and its associated data are deleted.
                $ stat file.txt # There is a link field in output which will be updated each time a new hard link is created
        2. Links have actual file contents
        3. Even if the original file is removed, the link will still show you the contents of the file ( because it is pointing to inode )
        4. You cannot create a hard link for a directory
        5. Hard links are only valid within the same File System. ( so creating links acrros Windows and Linux file system will not work ).

    Soft Link:
        ln -s <SOURCE> <LINK>
        SOURCE is the original file and LINK is the new file you will create that will point to the original source.

        Important Points:
            1. Soft Links will have different inode number, file size are different and permissions are also different ( verify it by [ ls -li <filename> ], first number is inode ? ).
            2. Soft link contains the path to the original file and not the contents
            3. Removing soft link doesn't affect anything, but when the original file is removed, the link becomes a 'dangling' link that points to nonexistent file
            4. Soft link can link to a directory
            5. Symbolic links can span file systems as they are simply the name of another file.
            6. when creating a dynamic library, we create soft link. so it be thought as pointer to a file.
            7. hard link can be used for backup.


    int lstat(const char *restrict pathname, struct stat *restrict buf );
        The lstat function is similar to stat, but when the named file is a symbolic link, lstat returns information about the symbolic link, not the file referenced by the symbolic link.

    int fstatat(int fd, const char *restrict pathname,struct stat *restrict buf, int flag);
        The fstatat function provides a way to return the file statistics for a pathname relative to an open directory represented by the fd argument. The flag argument controls whether symbolic links are followed. When the AT_SYMLINK_NOFOLLOW flag is set, fstatat will not follow symbolic links, but rather returns information about the link itself. Otherwise, the default is to follow symbolic links, returning information about the file to which the symbolic link points. If the fd argument has the value AT_FDCWD and the pathname argument is a relative pathname. If the pathname argument is an absolute pathname, then the fd argument is ignored. In these two cases, fstatat behaves like either stat or lstat, depending on the value of flag.

    Most files on a UNIX system are either regular files or directories, but there are additional types of files. The types are:
        1. Regular file. The most common type of file, which contains data of some form. There is no distinction to the UNIX kernel whether this data is text or binary. Any interpretation of the contents of a regular file is left to the application processing the file
        2. Directory file. A file that contains the names of other files and pointers to information on these files.
            Any process that has read permission for a directory file can read the contents of the directory, but only the kernel can write directly to a directory file.
        3. Block special file. A type of file providing buffered I/O access in fixed-size units to devices such as disk drives
        4. Character special file. A type of file providing unbuffered I/O access in variable-sized units to devices. All devices on a system are either block special files or character special files.
        5. FIFO. A type of file used for communication between processes. It’s sometimes called a named pipe
        6. Socket. A type of file used for network communication between processes.
            A socket can also be used for non-network communication between processes on a single host.
        7. Symbolic link. A type of file that points to another file.

    The type of a file is encoded in the st_mode member of the stat structure. We can determine the file type with the macros.
        S_ISREG() regular file
        S_ISDIR() directory file
        S_ISCHR() character special file
        S_ISBLK() block special file
        S_ISFIFO() pipe or FIFO
        S_ISLNK() symbolic link
        S_ISSOCK() socket

        /etc/passwd: regular
        /etc: directory
        /dev/log: socket
        /dev/tty: character special
        /dev/sr0: block special
        /dev/cdrom: symbolic link

14)
    The dirent structure defined in the file <dirent.h>
      struct dirent {
            ino_t d_ino;                  /* i-node number */
            char  d_name[NAME_MAX + 1];   /* null-terminated filename */
          }

    When you log into your UNIX system, you provide a username and a password at the login prompt. The login(1) program looks up that username in a database and obtains your registered password. It encrypts the password you supply at login and compares it to the one that is registered. If they are equal, the login(1) program lets you pass in peace. Once you are logged in, however, you become just a number to the UNIX kernel. This user ID number simplifies user and security management for the kernel. In addition to logging in with a user ID, you log in with a group ID.

    To find out what user ID number you are, the id(1) command can be used:
    $ id
    uid=1000(panther2) gid=1000(panther2) groups=1000(panther2),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),108(lpadmin),124(sambashare)
    The id(1) command indicates that the user panther2 is user ID number 100 and is a member of group number 1000. The user and group names are shown in brackets. These were obtained by looking up the user ID and group ID numbers in the password and group file databases, respectively. above informations are stored in inode and can be checked using [ stat <fielname> ]

    Linux is a multi-user system which means that more than one person can interact with the same system at the same time. User creation is handled with the useradd command.

    Groups are collections of zero or more users. A user belongs to a default group, and can also be a member of any of the other groups. The groups command prints the name of groups a user is part of. To view all the groups and members: $cat /etc/group

    groupadd command is used to create a new user group. To add a new user into the group, the group is mentioned using -g option in the command useradd. deluser program removes a user from a group. You can permanently remove a group with the groupdel command.

    All files and directories in Linux have a standard set of access permissions. These access permissions control who can access what files, and provides a fundamental level of security to the files and directories in a system. Linux divides authorization into 2 levels:
        Ownership
        Permission
    Every file and directory on your Unix/Linux system is assigned 3 types of owner:
        User:
            The username of the person who owns the file/directory. By default, the user who creates the file/directory will become its owner.
        Group:
            A user- group can contain multiple users. All users belonging to a group will have the same access permissions to the file.
        Other:
            Any other user who has access to a file. This person has neither created the file, nor he belongs to a usergroup who could own the file. Practically, it means everybody else.

    Permissions: Every file and directory in your UNIX/Linux system has following 3 permissions defined for all the 3 owners. Read, Write, Execute. You can view the permission of the current directory by typing the following command $ ls -l.
        r = read permission
        w = write permission
        x = execute permission
        - = no permission

        r = 4
        w = 2
        x = 1

    The chmod command is used to alter the permissions of a file. Every file is owned by a specific user (or UID) and a specific group (or GID). The chown command can be used to change just the user, or the user and group of a file. The basic format for the chown command is as follows:
    # chown user:group filename

    The st_size member of the stat structure contains the size of the file in bytes. This field is meaningful only for regular files, directories, and symbolic links. For a symbolic link, the file size is the number of bytes in the filename.

15)
    What is a Process? A program is a binary file on a storage medium; by itself, it is a dead object. When you run the program say from shell, it does indeed come alive, and become a process. A process is program that is running.

    To keep track of all these processes, your operating system gives each process a number - PID (Process ID). Processes also have a ppid which is short for parent process id. Process ID 0 is usually the scheduler process and is often known as the swapper. Process ID 1 is usually the init process(sysvinit) or systemd(systemd) and is invoked by the kernel at the end of the bootstrap procedure.

    run [ ps -ef | less ] and check 1 is assigned to systemd and if we use sysvinit then pid 1 is assigned to init. Ususally, it is first process. systemd and sysvinit are init managers and those start a process. systemd is newer and it is being adapted now.

    #include <unistd.h>
    System Call: pid_t getpid(void);
    Returns: process ID of calling process

    pid_t getppid(void);
    Returns: parent process ID of calling process

    Every process has six or more IDs associated with it.
        who we really are:
            - real user ID:The real user ID/group ID is the uid of the user who originally ran the process. These two fields are taken from our entry in the password file when we log in.
            - real group ID: When we execute a program file, the effective user ID of the process is usually the real user ID, and the effective group ID is usually the real group ID. Every file has an owner and a group owner.
    used for file access permission checks
            effective user ID
            effective group ID
    saved by exec functions
            saved set-user-ID
                The saved user ID is the process's original effective user ID. Upon an exec call, the kernel sets the Saved User ID to the effective user ID. This is used to switch back and forth between a privileged to unprivileged state for our process.
            saved set-group-ID
                However, we can also set a special flag in the file’s mode word (st_mode) that says, ‘‘When this file is executed, set the effective user ID of the process to be the owner of the file (st_uid).’’ Similarly, we can set another bit in the file’s mode word that causes the effective group ID to be the group owner of the file (st_gid). These two bits in the file’s mode word are called the set-user-ID bit and the set-group-ID bit. For example, if the owner of the file is the superuser and if the file’s set-user-ID bit is set, then while that program file is running as a process, it has superuser privileges. This happens regardless of the real user ID of the process that executes the file. As an example, the UNIX System program that allows anyone to change his or her password, passwd(1), is a set-user-ID program. This is required so that the program can write the new password to the password file, typically either /etc/passwd or /etc/shadow, files that should be writable only by the superuser.

    uid_t getuid(void);
    Returns: real user ID of calling process

    uid_t geteuid(void);
    Returns: effective user ID of calling process

    gid_t getgid(void);
    Returns: real group ID of calling process

    gid_t getegid(void);
    Returns: effective group ID of calling process

    When a program is executed, the process that does the exec can pass command-line arguments to the new program. Each program is also passed an environment list. Like the argument list, the environment list is an array of character pointers, with each pointer containing the address of a null-terminated C string. The address of the array of pointers is contained in the global variable environ. extern char **environ;

    Benefits of Virtual Memory:
        - freeing applications from having to manage a shared memory space,
        - increased security due to memory isolation,
        - being able to conceptually use more memory than might be physically available, using the technique of paging

    Each process has its own virtual memory. The amount of virtual memory depends on your system's architecture. Each OS handles virtual memory differently, but for most modern operating systems, the virtual memory of a process looks like this:
             address|-------------------| command-line arguments
                    |-------------------| and environment variables
                    |        stack      |
                    |-------------------|
                    |                   |
                    |                   |
                    |                   |
                    |-------------------|
                    |               heap|
                    |-------------------|
                    |uninitialized data | initialized to
                    |               (bss| zero by exec
                    |-------------------|
                    | initialized data  | read from
                    |-------------------| program file
                    |               text| by exec
        low address |-------------------|
                Typical memory arrangement

    High Memory Addresses : Command Line Arguments + Environmental Variables + Stack Growing downwards
    Low Memory Addresses:  Heap Growing Upwards + Executable

    The proc filesystem is a pseudo-filesystem which provides an interface to kernel data structures. It is commonly mounted at `/proc`. Most of it is read-only, but some files allow kernel variables to be changed.
        - /proc/[pid]/mem : This file can be used to access the pages of a process's memory through open(2), read(2), and lseek(2).
        - /proc/[pid]/maps :  A  file containing the currently mapped memory regions and their access permissions.

16)
    There are eight ways for a process to terminate. Normal termination occurs in five ways:
        1. Return from main
        2. Calling exit /* run [ man exit ] for more details, it is library call */
        3. Calling _exit or _Exit /* run [ man exit ] for more details, it is system call */
        4. Return of the last thread from its start routine
        5. Calling pthread_exit from the last thread
    Abnormal termination occurs in three ways
        6. Calling abort
        7. Receipt of a signal
        8. Response of the last thread to a cancellation request

    A call to exit() performs some basic shutdown steps, and then instruct the kernel to terminate the process. The function has no way of returning an error - in fact, it never returns at all. status parameter is used to denote the process's exit status. status & 0377 is returned to the parent. Before terminating the process, the C Library performs the following shutdown steps in order:
        1. Call any functions registered with atexit(), in the reverse order of their registration
        2. Flush all open standard I/O streams
        3. Remove any temporary files created with the tmpfile() function.
    The above operations are performed in user space, so exit() invokes the system call _exit() to let the kernel handle the rest of the termination process. The kernel cleans up the
        allocated memory,
        open files,
        System V Semaphores
        Destroys the process and notifies the parent of the child exit

17)
    An existing process can create a new one by calling the fork function. After a successful fork, execution in both the parent and child process continues at the instruction following the fork. Why does this happen? the job of fork is to make a (pretty much) identical copy of the parent in the child; this includes the hardware context (mentioned earlier), which of course includes the Instruction Pointer (IP) register (sometimes called the Program Counter (PC)) itself! Hence, the child process too will execute the user mode code at the same location as the parent.

    When fork() is executed the entire process memory is duplicated including the buffer. Thus the child process starts with a non-empty output buffer which will be flushed when the program exits. System administrators don't like fork-bombs and may set upper limits on the number of processes each user can have or may revoke login rights because it creates a disturbance in the force for other users' programs.

    #include <unistd.h>
    pid_t fork(void);
    Returns: 0 in child, process ID of child in parent, −1 on error

    The new process created by fork is called the child process. and already existing process is called parent process. This function is called once but returns twice. The only difference in the returns is that the return value in the child is 0, whereas the return value in the parent is the process ID of the new child. The reason the child’s process ID is returned to the parent is that a process can have more than one child, and there is no function that allows a process to obtain the process IDs of its children.

    The reason fork returns 0 to the child is that a process can have only a single parent, and the child can always call getppid to obtain the process ID of its parent (Process ID 0 is reserved for use by the kernel, so it’s not possible for 0 to be the process ID of a child.)

    The fork system call clones the current process to create a new process. It creates a new process (the child process) by duplicating the state of the existing process with a few minor differences. Thus, when a child process is created, the OS will copy the parent's
        text,
        data (three of them),
        library (and other mappings), plus
        the stack segment to the child.
    Hang on though; it does not stop there: There is more, much more, to a process than just its VAS.
        Open files
        Process credentials
        Scheduling information
        Filesystem (VFS) structures
        Paging tables
        Namespaces
        Signal dispositions
        Resource limits
        IPC structures
        Profiling (perf) information
        Security information:
        Thread stacks and TLS
        Hardware context

    The following attributes of the parent process are not inherited by the child process upon forking:
        PID
        PPID
        Locks
        Pending and blocked signals (cleared for child)
        Timers,
        alarms (cleared for child)
        Audit information (CPU/time counters are reset for child)
        Semaphore adjustments made via semop(2)
        Asynchronous IO (AIO) ops and contexts

    The child process does not start from main. Instead it returns from fork() just as the parent process does. In older UNIX systems, the entire address space of the parent process was directly copied (regardless of whether the resource was modified or not). These days, kernel performs copy-on-write, which saves a lot of resources, while being very time efficient.

    Modern implementations don’t perform a complete copy of the parent’s data, stack, and heap, since a fork is often followed by an exec. Instead, a technique called copy-on-write (COW) is used. These regions are shared by the parent and the child and have their protection changed by the kernel to read-only. If either process tries to modify these regions, the kernel then makes a copy of that piece of memory only, typically a ‘‘page’’ in a virtual memory system.

    In general, we never know whether the child starts executing before the parent, or vice versa. The order depends on the scheduling algorithm used by the kernel. If it’s required that the child and parent synchronize their actions, some form of interprocess communication is required.

    When a process terminates, either normally or abnormally, the kernel notifies the parent by sending the SIGCHLD signal to the parent. Because the termination of a child is an  asynchronous event—it can happen at any time while the parent is running — this signal is the asynchronous notification from the kernel to the parent. The parent can choose to ignore this signal, or it can provide a function that is called when the signal occurs: a signal handler. The default action for this signal is to be ignored.

    #include <sys/wait.h>
    pid_t wait(int *statloc);
    pid_t waitpid(pid_t pid, int *statloc, int options);

    a process that calls wait or waitpid can
        - Block, if all of its children are still running
        - Return immediately with the termination status of a child, if a child has terminated and is waiting for its termination status to be fetched
        - Return immediately with an error, if it doesn’t have any child processes
    The differences between these two functions are as follows:
        - The wait function can block the caller until a child process terminates, whereas waitpid has an option that prevents it from blocking
        - If the caller blocks and has multiple children, wait returns when one terminates. We can always tell which child terminated, because the process ID is returned by the function.

    The parent is notified via a signal, SIGCHLD, when the child process finishes but not vice versa.

    Do child processes share open filehandles? Yes! In fact both processes use the same underlying kernel file descriptor. For example if one process rewinds the random access position back to the beginning of the file, then both processes are affected. Both child and parent should close (or fclose) their file descriptors or file handle respectively.

    When a child finishes (or terminates) it still takes up a slot in the kernel process table.  Furthermore, they still contain information about the process that got terminated, such as process id, exit status, etc. (i.e. a skeleton of the original process still remains). Only when the child has been 'waited on' will the slot be available and the remaining information can be accessed by the parent. A long running program could create many zombies by continually creating processes and never wait-ing for them.

    Eventually there would be insufficient space in the kernel process table to create a new processes. Thus fork() would fail and could make the system difficult / impossible to use - for example just logging in requires a new process!

    int system(const char* cmd);
    system() is used to invoke an o.s cmd from c/c++ program. Using system(), we can execute any command that can be run on the terminal.

    The system call will fork, execute the command passed by parameter and the original parent process will wait for this to finish. This also means that system is a blocking call: The parent process can't continue until the process started by system exits. This may or may not be useful.

18)
    In Linux, the act of loading into memory and executing a program image is separate from the act of creating a new system process. One system call loads a binary program into memory, replacing the previous contents of the address space, and begins execution of the new program. This is called executing a new program. Provided by exec family of calls. Act of creating a new processs is called forking, and this functionality is provided by fork() system call.

    There is no single exec function; instead there is a family of exec functions
    Header File: #include <unistd.h>

    int execl(const char *path, const char *arg, ...);
    int execlp(const char *file, const char *arg, ...);
    int execle(const char *path, const char *arg,
                    ..., char * const envp[]);
    int execv(const char *path, char *const argv[]);
    int execvp(const char *file, char *const argv[]);
    int execvpe(const char *file, char *const argv[],
                    char *const envp[]);

    The process ID does not change across an exec, because a new process is not created; exec merely replaces the current process — its text, data, heap, and stack segments — with a brand-new program from disk. The base of each is exec (execute), followed by one or more letters which defines meaning of each call:
        e – An array of pointers to environment variables is explicitly passed to the new process image.
        l – Command-line arguments are passed individually (a list) to the function. You must include NULL after your last
       parameter.:
        p – Uses the PATH environment variable to find the file named in the file argument to be executed.
        v – Command-line arguments are passed to the function as an array (vector) of pointers.

    In Linux, only one member ( execve ) of the exec family is a system call. The rest are wrappers in the C Library around the system call (execve). This was done beacuse
        1. Variadic System Calls would be difficult to implement
        2. Concept of user's path exist in user space

    1. Fire up a shell
    2. In the window, or more precisely, at the shell prompt, type this: $ exec ps

    Yes, the terminal window process is the predecessor here; upon an exec it's overwritten by the successor process ps, which does its work and exits (you probably did not see the output as it disappeared too quickly). ps is the successor process, and, of course, we cannot return to the predecessor (the Terminal window)—ps has literally replaced its VAS. Thus, the Terminal window effectively disappears.

    1. Fire up a shell
    2. In the window, or more precisely, at the shell prompt, run ps followed by bash — yes, we're spawning a subshell here, followed by ps once more.
    $ps
    $bash
    $ps
    notice the PIDs of the original and sub-shell Bash processes

    3. On the sub-shell, exec the ps command; this ps successor process overwrites (or overlays) the process image of the predecessor process—the bash sub-shell. $exec ps
    4. Observe the output: In the exec ps command output, the PID of ps is the PID of the bash subshell process:
    5. Also notice we're back to the original bash shell process PID 3,396 now, as, of course, we cannot return to the predecessor.

    Key points during an exec operation:
        ---> The successor process overwrites (or overlays) the predecessor's virtual address space. In effect, the predecessor's text, data, library, and stack segments are now replaced by that of the successor's. The OS will take care of the size adjustments.
    ---> No new process has been created - the successor runs in the context of the old predecessor. Several predecessor attributes (including but not limited to the PID and open files) thus get auto-inherited by the successor.
    ---> On a successful exec, there is no possibility of returning to the predecessor; it's gone.

19)
    A signal is an event generated by the UNIX and Linux systems in response to some condition, upon receipt of which a process may in turn take some action. Signal can be thought of as software interrupt.

    Who can send signals?
        ----> Kernel to Process
        ----> Process to another Process
        ----> Process to itself
    note: no signal from process to kernel. also no kernel to kernel.

    What happens when the process receives a signal which it is not catching?
        ------>  the process will be terminated immediately
        ------>  a core dump file is created.
        ------>   This file, called core and placed in the current directory
        ------>   is an image of the process that can be useful in debugging

    types of signals in Linux:
        Two types:
        1. Maskable
            Maskable signals or interrupts in Linux are those signals which can be changed or ignored by the user. E.g. ctrl+c , ctrl+\
        2. Non Maskable
            Non-Maskable signals or interrupts are those interrupts which cannot be changed or ignored by the user. For example, Ctrl+Z. E.g. ctrl+z


    Meaning of each signals:
        - SIGHUP          ---->   If a process is being run from terminal and that terminal suddenly goes away then the process receives this signal. “HUP” is short for “hang up” and refers to hanging up the telephone in the days of telephone modems
        - SIGINT          ---->   The process was “interrupted”. This happens when you press Control+C on the controlling terminal.
        - SIGQUIT         ---->   Control+\
        - SIGILL          ---->   Illegal instruction. The program contained some machine code the CPU can't understand.
        - SIGTRAP         ---->   This signal is used mainly from within debuggers and program tracers
        - SIGABRT         ---->   The program called the abort() function. This is an emergency stop
        - SIGBUS          ---->   An attempt was made to access memory incorrectly. This can be caused by alignment errors in memory access etc.
        - SIGFPE          ---->   A floating point exception happened in the program.
        - SIGKILL         ---->   The process was explicitly killed by somebody wielding the kill program.
        - SIGUSR1         ---->   Left for the programmers to do whatever they want
        - SIGSEGV         ---->   An attempt was made to access memory not allocated to the process. This is often caused by reading off the end of arrays etc.
        - SIGUSR2         ---->   Left for the programmers to do whatever they want.
        - SIGPIPE         ---->   If a process is producing output that is being fed into another process that consume it via a pipe (“producer | consumer”) and the consumer dies then the producer is sent this signal.
        - SIGALRM         ---->   A process can request a “wake up call” from the operating system at some time in the future by calling the alarm() function. When that time comes round the wake up call consists of this signal.
        - SIGTERM         ---->   The process was explicitly killed by somebody wielding the kill program.
        - SIGSTKFLT       ---->   Stack fault on coprocessor
        - SIGCHLD         ---->   The process had previously created one or more child processes with the fork() function. One or more of these processes has since died.
        - SIGCONT         ---->   (To be read in conjunction with SIGSTOP.) If a process has been paused by sending it SIGSTOP then sending SIGCONT to the process wakes it up again (“continues” it).
        - SIGSTOP         ---->   (To be read in conjunction with SIGCONT.)If a process is sent SIGSTOP it is paused by the operating system. All its state is preserved ready for it to be restarted (by SIGCONT) but it doesn't get any more CPU cycles until then.
        - SIGTSTP         ---->   Essentially the same as SIGSTOP. This is the signal sent when the user hits Control+Z on the terminal. (SIGTSTP is short for “terminal stop”) The only difference between SIGTSTP and SIGSTOP is that pausing is only the default action for SIGTSTP but is the required action for SIGSTOP. The process can opt to handle SIGTSTP differently but gets no choice regarding SIGSTOP
        - SIGTTIN         ---->   The operating system sends this signal to a backgrounded process when it tries to read input from its terminal. The typical response is to pause (as per SIGSTOP and SIFTSTP) and wait for the SIGCONT that arrives when the process is brought back to the foreground
        - SIGTTOU         ---->   The operating system sends this signal to a backgrounded process when it tries to write output to its terminal. The typical response is as per SIGTTIN.
        - SIGURG          ---->   The operating system sends this signal to a process using a network connection when “urgent” out of band data is sent to it.
        - SIGXCPU         ---->   The operating system sends this signal to a process that has exceeded its CPU limit. You can cancel any CPU limit with the shell command “ulimit -t unlimited” prior to running make though it is more likely that something has gone wrong if you reach the CPU limit in make.
        - SIGXFSZ         ----->  The operating system sends this signal to a process that has tried to create a file above the file size limit. You can cancel any file size limit with the shell command “ulimit -f unlimited” prior to running make though it is more likely that something has gone wrong if you reach the file size limit in make.
        - SIGVTALRM       ----->  This is very similar to SIGALRM, but while SIGALRM is sent after a certain amount of real time has passed, SIGVTALRM is sent after a certain amount of time has been spent running the process.
        - SIGPROF         ----->  This is also very similar to SIGALRM and SIGVTALRM, but while SIGALRM is sent after a certain amount of real time has passed, SIGPROF is sent after a certain amount of time has been spent running the process and running system code on behalf of the process.
        - SIGWINCH        ----->  (Mostly unused these days.) A process used to be sent this signal when one of its windows was resized
        - SIGIO           ----->  (Also known as SIGPOLL.) A process can arrange to have this signal sent to it when there is some input ready for it to process or an output channel     has become ready for writing.
        - SIGPWR          ----->  A signal sent to processes by a power management service to indicate that power has switched to a short term emergency power supply. The process (especially long-running daemons) may care to shut down cleanlt before the emergency power fails
        - SIGSYS          ----->  Unused

    Sending signals from Keyboard:
        ----->  When you press CTRL+C key, a SIGINT  is sent which default action is to terminate the process
        -----> When you press CTRL+\ key, a SIGQUIT is sent which default action is to terminate the process dumping core
        -----> When you press CTRL+Z key, a SIGSTOP signal is sent that suspends the program

    Other common method is to use the kill command.
        kill -signal pid
        killall -signal binary
    The difference between kill and killall is that kill only sends signals to process identified by their pid, killall sends the signal to all process of a given name.

    With Signals, a process can asynchronously receive information about certain events or condition. A process can trap or subscribe to a signal; when this occurs, the process will asynchronously be notified of the fact by the OS, and will then run the code of a function in response: a signal handler.

    Examples:
        1. The developer wants to perform a common task: set up a timer and have it expire in, say, 1.5 seconds from now. How will the OS inform the process that the timer has expired?
        2. A process has an inadvertent defect (a bug); it makes an invalid memory access. subsystem (well, technically, the MMU and the OS) determines it must be killed. How exactly will it be killed?
        3. Linux's asynchronous IO (AIO) framework, and many other such scenarios.

    In C, send a signal to the child using kill POSIX call, Signals are also a key means for inter-process communication. One process can send a signal to another indicating that an action should be taken. To send a signal to a particular process, we use the kill() system call.
        int kill(pid_t pid, int signum);
        kill(child, SIGUSR1); // Send a user-defined signal

    How to handle Signals? The primary system call for signal handling is signal()

    int main()
    {
            signal(SIGPWR, powerFailureHandler);
            .......
    }
    void powerFailureHandler(int signum)
    {
            //Saves states to restore later
            .......
    }

    The first line in main() establishes a handler for the SIGPWR signals. Arguments:
    int signal(int signum, void (*handler)(int))
        first argument: signal number, such as SIGSTOP or SIGINT
        second argument: a function pointer type which points to the signal handler.

    the second argument to signal() is a function pointer, a reference to a function to call. This tells the operating system that whenever this signal is sent to this process, run this function as the signal handler. Also, the execution of the signal handler is asynchronous, which means the current state of the program will be paused while the signal handler executes, and then execution will resume from the pause point, much like context switching.

    What happens when forking? The child process inherits a copy of the parent's signal dispositions. In other words, if you have installed a SIGINT handler before forking, then the child process will also call the handler if a SIGINT is delivered to the child.

    The two signals that can never be ignored or handled are: SIGKILL and SIGSTOP.

20)
    The default action for things like SIGSEGV is to terminate your process but as you've installed a handler for it, it'll call your handler overriding the default behavior. But the problem is segfaulting instruction may be retried after your handler finishes and if you haven't taken measures to fix the first seg fault, the retried instruction will again fault and it goes on and on. So, in this program when we execute, it continously goes into sighandler.

    Can multiple signals be queued? No - however it is possible to have signals that are in a pending state. If a signal is pending, it means it has not yet been delivered to the process. The most common reason for a signal to be pending is that the process (or thread) has currently blocked that particular signal. If a particular signal, e.g. SIGINT, is pending then it is not possible to queue up the same signal again. It is possible to have more than one signal of a different type in a pending state. For example SIGINT and SIGTERM signals may be pending (i.e. not yet delivered to the target process).

    A SIGALRM signal is delivered by the Operating System via a request from the user occuring after some amount of time. Alarm can be set continually, but only one alarm is allowed per process. Subsequent calls to alarm() will reset the previous alarm. Suppose, now, that we want to write a program that will continually alarm every 1 second, we would need to reset the alarm once the signal is delivered. The natural place to do that is in the signal handler

    Blocking a signal means telling the operating system to hold it and deliver it later when it is unblocked. Between the time when it is generated and when it is delivered a signal is said to be pending. Generally, a program does not block signals indefinitely - it might as well ignore them by setting their actions to SIG_IGN.

    Is Blocking a signal similar to Ignoring a signal ? No, blocking a signal is different from ignoring a signal. When a process blocks a signal, the operating system does not deliver the signal until the process unblocks the signal. A process blocks a signal by modifying its signal mask with sigprocmask. But when a process ignores a signal, the signal is delivered and the process handles it by throwing it away.

    Temporary blocking of signals with sigprocmask gives you a way to prevent interrupts during critical parts of your code. If signals arrive in that part of the program, they are delivered later, after you unblock them. All signal blocking functions use a data structure called a signal set to specify what signals are affected. Thus, every activity involves two stages:
        1. creating the signal set, and
        2. then passing it as an argument to a library function.

    The collection of signals that are currently blocked is called the signal mask. Each process has its own signal mask. When you create a new process, it inherits its parent's mask. You can block or unblock signals with total flexibility by modifying the signal mask.

    What happens during fork? The child process inherits a copy of the parent process's signal disposition and a copy of the parent's signal mask. For example if SIGINT is blocked in the parent it will be blocked in the child too. For example if the parent installed a handler (call-back function) for SIG-INT then the child will also perform the same behavior. Pending signals however are not inherited by the child.

    What happens during exec? Both the signal mask and the signal disposition carries over to the exec-ed program. Pending signals are preserved as well. Signal handlers are reset, because the original handler code has disappeared along with the old process.

    What happens when a signal is received while already in a signal handler? the signal is delivered after the signal handler has finished.

21)
    What is strace? strace stands for system call tracer. It is a debugging tool that
        monitors the system calls used by a program and
        all the signals it receives.
    System calls are used by userspace applications when they need to do something that requires the kernel. strace may provide you with valuable information for many problem cases, for example: which config files really were read, which was the last file or shared library read before your program crashed, and so on

    What it does?
        ----> Learn which system calls a program make
        ----> Find those system calls that fail together with error code
        ----> Find which files a program opens
        ----> Find out what syscalls a running program is making, for example to see if it is struck in a loop

    Using strace is quite simple. There are two ways to let strace monitor a program.
        Method 1:
            $ strace program_name
            Ex: $ strace ls
            strace emits its entire output to stderr
        Method 2:
            If we want to monitor a process which is currently running we can attach to the process using –p option.
                $ strace –p <pid-of-the-application>

    strace is very useful while debugging crashes.  Some scenarios where strace can be helpful are –
        ----> When you don't have source code
        ----> program behaving poorly
        ----> nothing in the log files
        ----> nothing in stdout
        ----> no ports responding
        ----> don't want to open gdb
        ----> Debugging why an installation crashes on a machine.
        ----> Debugging random crashes that are most probably due to the program running out of memory or due to it requesting an arbitrarily large chunk of memory.
        ----> Finding out how the program interacts with the file system.
        ----> Debugging crashes reproducibly only on one machine.
        ----> Debugging crashes in unfamilar code or in cases when sources are unavailable.

    Child Processes: Sometimes the process you trace doesn't do the real work itself, but delegates it to child processes that it creates. If that's the case, you may want to pass -f to make strace "follow forks" and trace child processes, too, as soon as they're made. '-ff' - follows forks with separate output files per-fork

    Attaching strace to a running process: strace can also be attached to a running process and can be used to record its system calls. To do this, we must know the PID of the process which we want to debug. We can get this PID using the ps command.

    Sometimes the full syscall trace is too much. Using –e option we can also specify which system calls to be traced. To trace only open() and close() system calls use the following command: $ strace –e trace=’open,close’ <program-name>

    The -i option displays the instruction pointer at the time of each system call made by the program.

    ltrace is a debugging utility in Linux, used to display the calls a userspace application makes to shared libraries. Its name itself comes from library-call tracing. This tool is very useful for debugging user-space applications to determine which library call is failing.

    ltrace ./executable <parameters>

    ltrace(1) also allows you to selectively trace library calls when executed with the “-e” option and a set of calls to trace: $ ltrace -e malloc /bin/cat

    If you need to view the library calls from a live process, you can use ltrace(1)’s “-p” option: $ ltrace -p 2644. The parameter -c outputs the number and duration of the library calls that have occurred. $ ltrace -c ls /

22)
    What is a thread? A thread is a sequence of instructions within a process that can be executed independently of other code. Multiple threads within one process share:
        Heap
        Data
        Code
        open files (descriptors)
        signals and signal handlers
        current working directory
        User and group id

    Each thread will have its own
        Thread ID
        set of registers, stack pointer
        stack for local variables, return addresses
        signal mask
        priority

    Advantages of Threads:
        - Useful when you want to make a program appear to do two things at once. E.g. Real time word count on a document while still editing the text. One thread can manage the user's input and perform editing. The other thread will continuously update a word count variable.
        - Better utilization of hardware resources. We have laptops and desktops containing CPU's with multiple cores, using multiple threads inside a process can better utilize the hardware resources.
        - Context switch between threads is faster when compared to the context switch between processes ( add reason from Divy's message )

    Drawbacks of Threads:
        - We should carefully design multithreaded programs as most of the resources of the process are shared
        - Debugging a multithreaded program is much, much harder than debugging a single-thread program.

    gettid returns the caller's thread ID (TID). [ man 2 gettid ].

    if I want to pass more than one argument to thread function how can I accomplish that ? through array of argumnets and then pointer variable ?

    pthread_exit: When a thread terminates, it calls the pthread_exit function, much a process calls exit when it terminates. This function terminates the calling thread, returning a pointer to an object. Never return a pointer to a local variable, because the variable will be gone when the thread exits.
        #include <pthread.h>
        void pthread_exit(void *retval);

    pthread_join: pthread_join is the thread equivalent of wait that processes use to collect child processes.
        int pthread_join(pthread_t thread, void **thread_return);
        First parameter is the thread for which to wait
        Second argument is a pointer to pointer that itself points to the return value from the thread.

    What is the purpose of pthread_join?
        Wait for a thread to finish
        Clean up thread resources
        Grabs the return value of the thread

    What happens if you don't call pthread_join? Finished threads will continue to consume resources. Eventually, if enough threads are created, pthread_create will fail. In practice, this is only an issue for long-running processes but is not an issue for simple, short-lived processes as all thread resources are automatically freed when the process exits.

    pthread_join vs wait:
    Condition :
        A thread being waited for must have its detached state attribute set as joinable, not detached. None; any child process can (and in fact must) be waited upon.
    Hierarchy:
        None: any thread can join on any other thread; there is no requirement of a parent-child relationship. In fact, we do not consider threads to live within a strict parent-child hierarchy as processes do; all threads are peers. A strict parent-child hierarchy exists; only a parent can wait for a child process.
    Order:
        With threads, one is forced to join (wait) upon the particular thread specified as the parameter to pthread_join(3). With wait, a process can wait upon the death (or stoppage) of any child, or specify a particular child process to wait for with waitpid. So, it wait will complete for any of the child process.
    Signalling:
        No signal is sent upon a thread's death. Upon a process's death, the kernel sends the SIGCHLD signal to the parent process.

    Initially, your main() program comprises a single, default thread. All other threads must be explicitly created by the programmer. To create a thread use the function pthread_create. This function takes four arguments:
        int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg);
            The first is a pointer to a variable that will hold the id of the newly created thread.
            The second is a pointer to attributes that we can use to tweak and tune some of the advanced features of pthreads
            The third is a pointer to a function that we want to run
            Fourth is a pointer that will be given to our function

    when we create a new thread using pthread_create(), which thread will start executing first, the parent thread or the new thread ? no gurantee is given as to which thread will start executing first.

    what is the thing needs to be remembered for returned value? we need to rember that by the time pthread_join() collects the return value from the terminated thread, the thread might be recycled and the return value might be pointing to something else.

    what are some ways of handling the return value? as return value can never be a stack variable, there are two ways of handling the return variable.
        i) create a struct and pass it the pthread_create() function itself, which the thread function will fill it before exiting the  function.
        ii) use a global variable to pass the return value.
        iii) pass a specific location to the thread that is created detached, and let the main thread use the return value, when suits.

    The main thread, by invoking pthread_exit(3), has exited before the other threads in the process; the Linux kernel thus marks it as a zombie. How to prevent the main thread from becoming zombie? The answer is straightforward: do not allow the main thread to terminate before the other threads in the application. in other words, the recommendation is to always keep main() alive, waiting for all the other threads to die, before it itself terminates (and thus the process terminates).

    MultiProcess vs Mulithreads:
        fork.c ====>create and destroy a process by calling fork(2) and subsequently exiting in a loop (50000 times)
        $ time ./fork

        thread.c ===> create and destroy threads using pthread_create in a loop (50000 times)
        $ time ./thread

    Why is fork slower than thread ? Linux makes heavy use of the performance-enhancing copy-on-write(COW) memory techniques within its internal implementation of fork(2). Thus, it begs the question, if COW is heavily used, then what is slowing the fork down?

    The short answer:
        page table creation and setup cannot be COW-ed; it takes a while to do.
        When creating threads of the same process, this work (page table setup) is completely skipped.

    A far more accurate way to measure the time spent—and performance characteristics in general—is by using the well-known perf(1) utility.
    $ perf stat ./fork
    $ perf stat ./thread

    What is the difference between pthread_exit and pthread_join?
        - pthread_exit() will terminate the thread that is called.If you call it from your main thread,the main thread is terminated and your spawned threads continue execution. So anything you write after pthread_exit in the main thread will not be execcuted.This will be useful in a scenario in which your main thread has to just spawn threads.
        - pthread_join() will suspend the execution of the currently running thread until the particular thread you want is terminated,after that it resumes its execution.Useful where you have to wait until a particular thread completes its execution.

    If you write exit or return in your main thread, the whole process is terminated,but if you write pthread-exit in your main thread only that particular thread terminates and remaining threads continue their execution.

    Can you pass pointers to stack variables from one thread to another? Yes. However you need to be very careful about the lifetime of stack variables.

    With every thread some resources are associated like stack etc. When a thread exits ideally these resources should be reclaimed by process automatically. But that doesn’t happens always. It depends on which mode thread is running.

    A Thread can run in two modes i.e.
        Joinable Mode
        Detached Mode

    By default a thread runs in joinable mode. Joinable thread will not release any resource even after the end of thread function, until some other thread calls pthread_join() with its ID. A Detached thread automatically releases it allocated resources on exit. No other thread needs to join it. But by default all threads are joinable, so to make a thread detached we need to call pthread_detach() with thread id.

23)
    In C, we use fork() to create new process and pthread_create to create a new thread. Both internally uses clone system call provided by Linux Kernel. You can see from strace, in both thread and process creation, clone system call is used and arguments are changed.

    Following are the options user can specify while clone():
        1. CLONE_VM: Virtual Memory is shared between the calling process and child process. That is if any of the calling process or child process modify the memory it will be visible in the other process.
        2. CLONE_FS: File system attributes are shared. E.g. root directory, current working directory, file mode creation mask.
        3. CLONE_FILES: If set, Parent and Child will share the table of open file descriptors. These descriptors are those values returned by open, socket, pipe etc. Modification in child will also modify the file descriptor table in parent.
        4. CLONE_SIGHAND: If set, Parent and child processes will share the same signal handler table. Modification by one process will affect the other process.
        5. CLONE_THREAD: Child is placed in the same thread group id as the parent. It means the pid of the parent and child will be the same, but the thread id will be different. You can get thread id by calling gettid() API.

    $ strace ./1_thread | grep clone
    $ strace ./2_fork | grep clone
    check which call use which options in clone and see how thread is fast compared to fork

    Can you fork a process with multiple threads?

    What is the expected output of the program?
    Ans: 2*loops

    If you say the above answer it is wrong, because the increment is not an atomic operation. Increment when converted to assembly will not be in single instruction.Hence the difference. One way to solve is to make increment atomic. This can be done by using atomic operator provided by GNU. The above code suffers from a race condition - the value of i is changing. The new threads start later (in the example output the last thread starts after the loop has finished). To overcome this race-condition, we will give each thread a pointer to it's own data area. These are synchronization locks that are used to prevent race conditions and ensure proper synchronization between threads running in the same program.

    Stack Location: Where in memory (technically, where in the VAS of the given process) does the thread stack actually reside? The stack of the main thread is always situated at the very top of the process VAS. The stacks of all other threads in the process are located somewhere between the process heap segment and the stack of main.

    OS and threading system to arrange to multiplex the threads on the CPUs. Each thread is given a turn on some CPU. When it goes to do I/O, or a fixed amount of time has expired, the OS pauses the thread (saving off all of its machine state), and selects another thread to run. It then loads the saved machine state from the new thread onto the CPU and starts that thread at the spot where it last left off (or at the beginning if it was just created). The process of pausing one thread to run another is called pre-emption and the second thread is said to pre-empt the first. The process of switching to a new thread (as a result of a pre-emption event) is called context switching and the saved machine state that is necessary to get a thread running again after a pause is often called a context.

    When multiple threads of control share the same memory, we need to make sure that each thread sees a consistent view of its data. If each thread uses variables that other threads don’t read or modify, no consistency problems will exist Similarly, if a variable is read-only, there is no consistency problem with more than one thread reading its
    value at the same time. However, when one thread can modify a variable that other  threads can read or modify, we need to synchronize the threads to ensure that they don’t use an invalid value when accessing the variable’s memory contents.

    In this example, thread A reads the variable and then writes a new value to it, but the write operation takes two memory cycles. If thread B reads the same variable between the two write cycles, it will see an inconsistent value.
        Thread A        Thread B
        read
        write1
                        read
        write2

    A critical section is a section of code that can only be executed by one thread at a time, if the program is to function correctly. If two threads (or processes) were to execute code inside the critical section at the same time then it is possible that program may no longer have correct behavior.

    Mutex: A mutex is basically a lock that we set (lock) before accessing a shared resource and release (unlock) when we’re done. While it is set, any other thread that tries to set it will block until we release it. If more than one thread is blocked when we unlock the mutex, then all threads blocked on the lock will be made runnable, and the first one to run will be able to set the lock. A mutex variable is represented by the pthread_mutex_t data type.

    If the mutex is unlocked at the time pthread_mutex_trylock is called, then pthread_mutex_trylock will lock the mutex without blocking and return 0. Otherwise, pthread_mutex_trylock will fail, returning EBUSY without locking the mutex.

    A thread will deadlock itself if it tries to lock the same mutex twice. When we use more than one mutex in our programs, a deadlock can occur if we allow one thread to hold a mutex and block while trying to lock a second mutex at the same time that another thread holding the second mutex tries to lock the first mutex.  Neither thread can proceed, because each needs a resource that is held by the other, so we have a deadlock.


    No, the other threads will continue. It's only when a thread attempts to lock a mutex that is already locked, will the thread have to wait.

    Can I create mutex before fork-ing? Yes - however the child and parent process will not share virtual memory and each one will have a mutex independent of the other.

    If one thread locks a mutex can another thread unlock it? No. The same thread must unlock it.


    What is the Reader Writer Problem?
    There is a shared resource which should be accessed by multiple processes. There are two types of processes in this context. They are reader and writer. Any number of readers can read from the shared resource simultaneously, but only one writer can write to the shared resource. When a writer is writing data to the resource, no other process can access the resource. A writer cannot write to the resource if there are non zero number of readers accessing the resource at that time.

    read() {
      lock(&m)
      // do read stuff
      unlock(&m)
    }

    write() {
      lock(&m)
      // do write stuff
      unlock(&m)
    }

    At least our first attempt does not suffer from data corruption (readers must wait while a writer is writing and vice versa)! However readers must also wait for other readers.

    Reader-Writer Locks: Reader–writer locks are similar to mutexes, except that they allow for higher degrees of parallelism. With a mutex, the state is either locked or unlocked, and only one thread can lock it at a time. Three states are possible with a reader–writer lock:
        locked in read mode,
        locked in write mode, and
        unlocked.

    Only one thread at a time can hold a reader–writer lock in write mode, but multiple threads can hold a reader–writer lock in read mode at the same time. When a reader–writer lock is write locked, all threads attempting to lock it block until it is unlocked. When a reader–writer lock is read locked, all threads attempting to lock it in read mode are given access, but any threads attempting to lock it in write mode block until all the threads have released their read locks.

    Reader–writer locks are well suited for situations in which data structures are read more often than they are modified. Reader–writer locks are also called shared–exclusive locks. When a reader–writer lock is read locked, it is said to be locked in shared mode. When it is write locked, it is said to be locked in exclusive mode. As with mutexes, reader–writer locks must be initialized before use and destroyed before freeing their underlying memory.

        #include <pthread.h>
        int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);
        int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);

    A reader–writer lock is initialized by calling pthread_rwlock_init. We can pass a null pointer for attr if we want the reader–writer lock to have the default attributes. Before freeing the memory backing a reader–writer lock, we need to call pthread_rwlock_destroy to clean it up. To lock a reader–writer lock in read mode, we call pthread_rwlock_rdlock. To  write lock a reader–writer lock, we call pthread_rwlock_wrlock. Regardless of how we lock a reader–writer lock, we can unlock it by calling pthread_rwlock_unlock.

24)
    What Is A Condition Variable? A condition variable is a mechanism that allows threads to wait (without wasting CPU cycles) for some even to occur. Several threads may wait on a condition variable, until some other thread signals this condition variable (thus sending a notification).

    At this time, one of the threads waiting on this condition variable wakes up, and can act on the event. It is possible to also wake up all threads waiting on this condition variable by using a broadcast method on this variable. Note that a condition variable does not provide locking. Thus, a mutex is used along with the condition variable, to provide the necessary locking when accessing this condition variable.

    Creation of a condition variable requires defining a variable of type pthread_cond_t, and initializing it properly. We can assign the constant PTHREAD_COND_INITIALIZER to a statically allocated condition variable, but if the condition variable is allocated dynamically, we can use the pthread_cond_init function to initialize it. We can use the pthread_cond_destroy function to deinitialize a condition variable before freeing its underlying memory.
        #include <pthread.h>
        int pthread_cond_init(pthread_cond_t *restrict cond,
        const pthread_condattr_t *restrict attr);
    Unless you need to create a conditional variable with nondefault attributes, the attr argument to pthread_cond_init can be set to NULL.

        int rc = pthread_cond_signal(&got_request);
    Or by using the broadcast function:
        int rc = pthread_cond_broadcast(&got_request);

    Waiting On A Condition Variable: If one thread signals the condition variable, other threads would probably want to wait for this signal. They may do so using one of two functions, pthread_cond_wait() or pthread_cond_timedwait(). Each of these functions takes a condition variable, and a mutex (which should be locked before calling the wait function), unlocks the mutex, and waits until the condition variable is signaled, suspending the thread's execution.

    If this signaling causes the thread to awake (see discussion of pthread_cond_signal() earlier), the mutex is automagically locked again by the wait funciton, and the wait function returns. The only difference between these two functions is that pthread_cond_timedwait() allows the programmer to specify a timeout for the waiting, after which the function always returns, with a proper error value (ETIMEDOUT) to notify that condition variable was NOT signaled before the timeout passed. The pthread_cond_wait() would wait indefinitely if it was never signaled.

    What does pthread_cond_wait do? The call pthread_cond_wait performs three actions:
        1. unlock the mutex
        2. waits (sleeps until pthread_cond_signal is called on the same condition variable). It does 1 and 2 atomically.
        3. Before returning, locks the mutex

    Why do Condition Variables also need a mutex?
        Reason 1: The simplest to understand is that it prevents an early wakeup message (signal or broadcast functions) from being 'lost.'. Imagine the following sequence of events (time runs down the page) where the condition is satisfied just before pthread_cond_wait is called. In this example the wake-up signal is lost!
            Thread 1            Thread 2
            while (answer < 42) {
                            answer++
                            p_cond_signal(cv)
            p_cond_wait(cv, m)
        If both threads had locked a mutex, the signal can not be sent until after pthread_cond_wait(cv, m) is called (which then internally unlocks the mutex)
        Reason 2: A second common reason is that updating the program state (answer variable) typically requires mutual exclusion - for example multiple threads may be updating the value of answer.

    Thread Cancellation: Cancellation allows one thread to terminate another. One reason you may want to cancel a thread is to save system resources (such as CPU time) when your program determines that the thread's activity is no longer necessary. A simple example of a thread you might want to cancel would be a thread performing a read-only data search. If one thread returns the results you are looking for, all other threads running the same routine could be canceled. When we want to terminate a thread, we can use the pthread_cancel function. This function gets a thread ID as a parameter, and sends a cancellation request to this thread. It will only sends request, doesn't cancel.

    Barriers: How do I wait for N threads to reach a certain point before continuing onto the next step? Suppose we wanted to perform a multi-threaded calculation that has two stages, but we don't want to advance to the second stage until the first stage is completed. We could use a synchronization method called a barrier. When a thread reaches a barrier, it will wait at the barrier until all the threads reach the barrier, and then they'll all proceed together.

    Think of it like being out for a hike with some friends. You agree to wait for each other at the top of each hill (and you make a mental note how many are in your group). Say you're the first one to reach the top of the first hill. You'll wait there at the top for your friends. One by one, they'll arrive at the top, but nobody will continue until the last person in your group arrives. Once they do, you'll all proceed.

    The thread calling pthread_barrier_wait is put to sleep if the barrier count (set in the call to pthread_barrier_init) is not yet satisfied. If the thread is the last one to call pthread_barrier_wait, thereby satisfying the barrier count, all of the threads are awakened.

    When you create many threads that cooperate to accomplish a single task, you must sometimes perform a single operation up front so that all of these threads can proceed. For instance, you may need to open a file or initialize a mutex. Up to now, we've had our boss thread handle these chores, but that's not always feasible. The pthread_once mechanism is the tool of choice for these situations.

    It, like mutexes and condition variables, is a synchronization tool, but its specialty is handling synchronization among threads at initialization time. If the pthread_once function didn't exist, we'd have to initialize all data, mutexes, and condition variables before we could create any thread that uses them.

    Per-thread signal masks: Like a traditional process, a thread has a signal mask that indicates which asynchronous signals it's willing to handle (these are considered unblocked) and which ones it's not (these are considered blocked). threads inherit the signal mask of the thread that issued the pthread_create that created them. Use the pthread_sigmask call to block and unblock signals in the mask. When an asynchronously generated signal arrives at a process, it is handled once by exactly one thread in the process. The system selects this thread by referring to the collection of per-thread signal masks of all the threads.  If more than one thread has the signal unblocked, the system arbitrarily selects one of them.

    What happens to a multithreaded Linux process if it gets a signal? Each thread has its own signal mask, but the signal disposition is shared by all threads in the process. As a consequence, individual threads can block signals, but when a thread modifies the action associated with a given signal, all threads share the action. Thus, if one thread chooses to ignore a given signal, another thread can undo that choice by restoring the default disposition or installing a signal handler for that signal.

    "Private" thread data - Thread-Specific Data: In "normal", single-thread programs, we sometimes find the need to use a global variable. It is frequently a bad practice to have global variables, but they sometimes do come handy. Especially if they are static variables - meaning, they are recognized only on the scope of a single file. In multi-threaded programs, we also might find a need for such variables. We should note, however, that the same variable is accessible from all the threads, so we need to protect access to it using a mutex, which is extra overhead. Further more, we sometimes need to have a variable that is 'global', but only for a specific thread. Or the same 'global' variable should have different values in different threads.

    For example, consider a program that needs to have one globally accessible linked list in each thread, but not the same list. Further, we want the same code to be executed by all threads. In this case, the global pointer to the start of the list should be point to a different address in each thread. In order to have such a pointer, we need a mechanism that enables the same global variable to have a different location in memory. This is what the thread-specific data mechanism is used for.

    Keys with the same name in two separate threads always point to different memory locations - this is handled by the library functions that allocate memory blocks to be accessed via these keys.

25)
    What is IPC? Inter process communication is any way for one process to talk to another process. Signals was one kind of IPC Mechanism.

    What is a pipe? We use the term pipe to mean connecting a data flow from one process to another. Generally you attach or pipe the output of one process to the input of another. For shell commands, this is done using the pipe character to join the commands
        $ command1 | command2

        1. The standard input to command1 will comes from the terminal keyboard
        2. The standard output from command1 is fed to command2 as its standard input
        3. The standard output from command2 is connected to the terminal screen.

    A pipe is created by calling the pipe function.
        #include <unistd.h>
        int pipe(int fd[2]);
            --> pipe is passed (a pointer to) an array of two integer file descriptors.
            --> it fills the array with two new file descriptors and returns a zero.
            --> The two file descriptors returned are connected in a special way.
            --> Any data written to file_descriptor[1] can be read back from file_descriptor[0].
            --> The first element of the array is the reading-end of the pipe, the second is the writing end.

    You should be aware that the effect of trying to write using file_descriptor[0] or read using file_descriptor[1] is undefined. A pipe in a single process is next to useless. Normally, the process that calls pipe then calls fork, creating an IPC channel from the parent to the child, or vice versa. fork() man page tells us that the child will receive a copy of all the parent's file descriptors, and this includes a copy of the pipe's file descriptors.

    The mistake in above code is that there is still a reader for the pipe! The child still has the pipe's first file descriptor open. When forking, It is common practice to close the unnecessary (unused) end of each pipe in the child and parent process. For example the parent might close the reading end and the child might close the writing end (and vice versa if you have two pipes).

    What happens if a child process won't close the pipe from writing, while reading? If the process — parent or child — is not going to use the write end of a pipe, it should close that file descriptor. Similarly for the read end of a pipe. The system will assume that a write could occur while any process has the write end open, even if the only such process is the one that is currently trying to read from the pipe, and the system will not report EOF,

    How to check if the pipe is opened before writing? If I write a message to a closed pipe then program will crash

    Named Pipes/FIFO: Unnamed pipes (the kind we've seen up to this point) live in memory (do not take up any disk space) and are a simple and efficient form of inter-process communication (IPC) that is useful for streaming data and simple messages. Once all processes have closed, the pipe resources are freed. Unnamed pipes can be used only between related processes when a common ancestor has created the pipe. An alternative to unamed pipes is named pipes created using mkfifo. FIFOs are sometimes called named pipes. With FIFOs, however, unrelated processes can exchange data

    a FIFO is a type of file. One of the encodings of the st_mode member of the stat structure indicates that a file is a FIFO. We can test for this with the S_ISFIFO macro. Creating a FIFO is similar to creating a file. Indeed, the pathname for a FIFO exists in the file system.
        #include <sys/stat.h>
        int mkfifo(const char *path, mode_t mode);
        int mkfifoat(int fd, const char *path, mode_t mode);

26)
    three different mechanisms for inter-processes communication:
        Message queues : pass messages between processes
        Semaphores : synchronize for multiple processes by kernel
        Shared memory: share region of memory

    Shared Memory: POSIX shared memory is an inter-process communication (IPC) mechanism defined in POSIX specification. Shared memory is the fastest form of IPC available. Once the memory is mapped into the address space of the processes that are sharing the memory region, no kernel involvement occurs in passing data between the processes.

    What we mean by ‘‘no kernel involvement’’?  the processes do not execute any system calls into the kernel to pass the data. The problem with these forms of IPC—pipes, FIFOs, and message queues—is that for two processes to exchange information, the information has to go through the kernel. Shared memory provides a way around this by letting two or more processes share a region of memory. The processes must, of course, coordinate or synchronize the use of the shared memory among themselves.
    $man 7 shm_overview

    Use case of shared memory: As a simple example you could reserve just a few bytes and change the value in shared memory when you want the child process to quit.

    problem: sysnchronization is not taken care by kernel. We have to do that.

    share memory objects have kernel persistence. Shared memory object will exist untill the system is shut down or untill all processes have umapped the object and it has been deleted with shm_unlink(). shared memory objects are created in tmpfs virtual filesystem and mounted under /dev/shm. tmpfs in mounted on /dev/shm and it similar to a filesystems like /proc.

    mmap, munmap: map or unmap files or devices into memory
     void *mmap(void *addr, size_t length, int prot, int flags,
                      int fd, off_t offset);
     int munmap(void *addr, size_t length);
      mmap()  creates a new mapping in the virtual address space of the calling process.
        addr -- the starting address for the new mapping. If NULL, the kernel chooses the address at which to create the mapping
        length -- specifies the length of the mapping
        prot -- describes the memory protection of the mapping
            PROT_EXEC  Pages may be executed.
            PROT_READ  Pages may be read.
            PROT_WRITE Pages may be written.
            PROT_NONE  Pages may not be accessed
        flags -- determines whether updates to the mapping are visible to other processes mapping the same region
            MAP_SHARED      Share  this  mapping
            MAP_PRIVATE Create a private copy-on-write mapping.

    Memory mapped by mmap() is preserved across fork(2), with the same attributes. Use of a mapped region can result in these signals:
    SIGSEGV            Attempted write into a region mapped as read-only.

    Can I ftruncate a shared memory object after it has ben mmap'ed? You can truncate the underlying file anytime

27)
    Anonymous Mapping: MAP_ANONYMOUS
        The mapping is not backed by any file;
        its contents are initialized to zero.
        The fd and offset arguments are ignored;

    man 2 msync. One key issue with memory-mapped files is the timing of when updates get copied back into the file on disk. For instance, if another process opens and reads the file using read(), will this other process see any updates that were written to the memory-mapped region? The answer is that it depends on a number of timing factors.
        - The first factor is the kernel itself. When a file is mapped into memory with mmap(), the kernel will occasionally trigger a write to copy updated portions back to disk.
        - A second factor is the file system of the underlying file. Some file systems do not commit changes to the file until the writing process has closed its connection to the file.

    Processes can insert control over this issue by using the msync() function. This function takes a flags parameter that can initiate a synchronous, blocking write (MS_SYNC) or an asynchronous, non-blocking one (MS_ASYNC). In the case of the asynchronous write, the data will get copied to disk at a later point; however, the updated data would be immediately available to any process that reads from the file with read().

    Memory Mapped I/O:
    Memory-mapped I/O lets us map a file on disk into a buffer in memory so that
        when we fetch bytes from the buffer, the corresponding bytes of the file are read.
        when we store data in the buffer, the corresponding bytes are automatically written to the file
    This lets us perform I/O without using read() or write(). To use this feature, we have to tell the kernel to map a given file to a region in memory. This is done by the mmap function.

    How does the operating system load my process and libraries into memory? It maps the executable and library file contents into the address space of the process. If many programs only need read-access to the same file (e.g. /bin/bash, the C library) then the same physical memory can be shared between multiple processes

    Memory-mapped files have several uses and advantages over traditional file access functions:
        1. Memory-mapped files allow for multiple processes to share read-only access to a common file. Eg. the C standard library (glibc.so) is mapped into all processes running C programs. only one copy of the file needs to be loaded into physical memory, even if there are thousands of programs running.
        2. Rather than using fseek() multiple times to jump to random file locations, the data can be accessed directly by using an index into an array.
        3. Memory-mapped files provide more efficient access for initial reads. When read() is used to access a file, the file contents are first copied from disk into the kernel's buffer cache. Then, the data must be copied again into the process's user-mode memory for access. Memory-mapped files bypass the buffer cache, and the data is copied directly into the user-mode portion of memory.

28)
    Semaphores: Semaphores are used for process and thread synchronization. A semaphore is an integer whose value is never allowed to fall below zero. Two operations can be performed on semaphores:
        - increment the semaphore value by one (sem_post(3))
        - and decrement the semaphore value by one (sem_wait(3))
    If the value of a semaphore is currently zero, then a sem_wait(3) operation will block until the value becomes greater than zero.

    Types of Semaphores:
        - Named: Named semaphores have a name, which is of the format /somename. The first character is a forward slash, followed by one or more characters, none of which is a slash.
        - Unnamed Semaphores: The sem_init() function initializes the unnamed semaphore specified by the sem argument and assigns that semaphore the value specified by the value argument. Once the semaphore has been successfully initializes, you can use it in subsequent calls to sem_wait and sem_post.

    Message Queue: in pipe and queue, there is no boundary on message and no way to distinguish. But, here we can do it.$ man 7 mq_overview

    POSIX message queues allow processes to exchange data in the form of messages. General usage for message queues is as follows:
        1. Get a message queue descriptor with a call to the mq_open function.
        2. Send and receive messages with calls to the mq_send and mq_receive functions.
        3. Close the message queue with a call to the mq_close function.
        4. Remove the message queue with a call to the mq_unlink function.

    Once a message queue is open, you can send messages to another process using the mq_send function.
        int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len, unsigned int msg_prio);
        The mq_send function takes four parameters, including:
            the message queue descriptor,
            a pointer to a message buffer,
            the size of the buffer, and
            the message priority

    The read/write permissions are checked along with the length of the message, the status of the message queue, and the message flag. If all checks are successful, the message is added to the message queue. If the queue is already full, the sending process can block until space in the queue becomes available. it can return immediately, if we set the O_NONBLOCK flag when it called the mq_open function.

    Receiving Messages: Once a message has been placed on a queue, you can retrieve the message with a call to the mq_receive function.
        ssize_t mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len, unsigned int *msg_prio);
        The mq_receive function includes four parameters:
            the message queue descriptor,
            a pointer to a buffer to hold the incoming message,
            the size of the buffer,
            and the priority of the message received (the priority is returned by the function)

    The size of the buffer must be at least the size of the message queue's size attribute. When a process uses the mq_receive function to read a message from a queue, the queue may be empty. The receiving process can block until a message arrives in the queue, or it can return immediately, according to the state of the O_NONBLOCK flag established with a preceding call to the mq_open function.

    If more than one process is waiting to receive a message when a message arrives at an empty queue, then the process with the highest priority that has been waiting the longest is selected to receive the message.

    Asynchronous Notification of Messages: A process that wants to read a message from a message queue has three options:
        - Set the queue to blocking mode, and wait for a message to be received by calling mq_receive
        - Set the queue to non-blocking mode, and call mq_receive multiple times until a message is received
        - Set the queue to non-blocking mode, and call mq_notify specifying a signal to be sent when the queue goes from empty to non-empty

    The last option is a good choice for a realtime application.

    The mq_notify function is used to register a request for asynchronous notification by a signal when a message becomes available on a previously empty queue. The process can then do useful work until a message arrives, at which time a signal is sent according to the signal information specified in the notification argument of the mq_notify function. After notification, the process can call mq_receive to receive the message.

29)
    Sockets: Sockets provide point-to-point, two-way communication between two processes (Unix domain sockets/IPC Sockets). Sockets can also be used to communicate between processes on different systems.(Network Sockets). Sockets are used in a Client-Server model.

    Client - Server Setup: Sockets are used as follows:
        each application: create a socket
        server: bind its socket to a well-known address
        client: locate server socket (via its well-known address) and “initiate communication” with the server

    Socket Creation: Sockets are created using the socket syscall which returns a file descriptor to be used for further operations on the underlying socket
        #include <sys/socket.h>
        int socket(int domain, int type, int protocol);
            Each triple hdomain, type, protocol identifies a different “species” of sockets
                - domain differentiates if we are using IPC or network socket. If we use AF_UNIX, then it means IPC else network socket. domain: AF_UNIX, AF_INET, AF_INET6
                - type: SOCK_STREAM, SOCK_DGRAM

    SOCK_STREAM: TCP protocol, reliable communication
    SOCK_DGRAM: UDP protocol, less reliable communication

    The file descriptor returned upon success is used to further reference the socket, for both communication and setup purposes. we can't use normal file as socket, check in code how socket is being created.

    Binding sockets to a well-known address: To allow connections from other, we need to bind sockets to well-known addresses using bind
        #include <sys/socket.h>
        int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
            - sockfd references the socket we want to bind
            - addrlen/addr are, respectively, the length and the structure containing the well-known address we want to bind the socket to. The actual type of the addr structure depends on the socket domain.

    The address format varies with the domain:
        - UNIX domain uses pathnames
        - Internet domains use IP addresses

    bind is a generic system call that can bind sockets in any domain. each socket domain has its own variant of sockaddr. you will fill the domain-specific struct and cast it to struct sockaddr before passing it to bind. bind will use sa_family to determine how to use sa_data

    struct sockaddr {
        sa_family_t sa_family ; /* address family ( AF_ * ) */
        char sa_data[14]; /* socket address ( size varies with the socket domain ) */
    }

    When you bind a unique name to a UNIX domain socket by using the bind function, a file is created on the file system for the socket. [ls -l] in file if start from s, it means it is socket.

    The actual filesystem entry is created at bind time. If the file already exists, bind will fail. It’s up to you to remove stale sockets as needed.

    Listening connections: listen allow to accept incoming connections
        #include <sys/socket.h>
        int listen (int sockfd, int backlog);
            - sockfd references the socket we want to affect
            - backlog specifies the maximum number of pending connections that the socket will keep. The backlog argument provides a hint to the implementation which the implementation shall use to limit the number of outstanding connections in the socket's listen queue.

    Accepting connections:
        #include <sys/socket.h>
        int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);

            server          client
    -----------------------------------------
    socket()
    bind()
    listen()
                            socket()
    accept()                connect()
    send() & recv()         send() & recv()
    close()                 close()

    Once a connection between two peer socket is established, communication happens via read/write on the corresponding file descriptors.

    Named Pipes vs Sockets:
        Duplex
            Stream sockets provide bi-directional communication while named pipes are uni-directional.
        Distinct clients
            Clients using sockets each have an independent connection to the server.
            With named pipes, many clients may write to the pipe, but the server cannot distinguish the clients from each other-- the server has only one descriptor to read from the named pipe.
            Since pipes have these limitations, UNIX domain sockets should be used if there are multiple clients that need to be distinguishable or which write long messages to the server.

    Method of Creating and opening:
        Sockets are created using socket and assigned their identity via bind.
        Named pipes are created using mkfifo.
        To connect to a UNIX domain socket the normal socket/connect calls are used, but a named pipe is written using regular file open and write
        That makes them easier to use from a shell script for example.

    For bidirectional communication you need to call bind(), listen() and so many. there's a beauty of a system call known as socketpair() this is nice enough to return to you a pair of already connected sockets!  The pair of sockets is unnamed; that is, they are not bound to a file path. No extra work is needed on your part; you can immediately use these socket descriptors for interprocess communication. If you want two separate programs to communicate (eg. you have an executable called client, and one called server), you can't use this mechanism.

    Netstat is a command line utility that can be used to list out all the network (socket) connections on a system. It lists out all the:
        tcp,
        udp  and
        the unix socket connections.

    Linux Abstract Socket Namespace: Linux has a special feature: if the pathname for a UNIX domain socket begins with a null byte \0, its name is not mapped into the filesystem. Thus it won’t collide with other names in the filesystem. Also, when a server closes its UNIX domain listening socket in the abstract namespace, its file is deleted. with regular UNIX domain sockets, the file persists after the server closes it.

    SOCK_STREAM vs SOCK_DGRAM: In case if AF_INET, SOCK_STREAM uses TCP (reliable) and SOCK_DGRAM used udp (unreliable). Unix sockets are always reliable. The difference between SOCK_STREAM and SOCK_DGRAM is in the semantics of consuming data out of the socket.

    Stream socket allows for reading arbitrary number of bytes, but still preserving byte sequence. In other words, a sender might write 4K of data to the socket, and the receiver can consume that data byte by byte. The other way around is true too - sender can write several small messages to the socket that the receiver can consume in one read. Stream socket does not preserve message boundaries.

    Datagram socket, on the other hand, does preserve these boundaries - one write by the sender always corresponds to one read by the receiver(even if receiver's buffer given to read(2) or recv(2) is smaller then that message). So if your application protocol has small messages with known upper bound on message size you are better off with SOCK_DGRAM since that's easier to manage.

    If your protocol calls for arbitrary long message payloads, or is just an unstructured stream (like raw audio or something), then pick SOCK_STREAM and do the required buffering.
