Theory0:
In C, we use fork() to create new process and pthread_create to create a new thread. Both internally uses clone system call provided by Linux Kernel.

To find the system call: 
$ strace ./1_thread
$ strace ./2_fork

You can see from strace, in both thread and process creation, clone system call is used and arguments are changed.

Following are the options user can specify while clone():
1. CLONE_VM: Virtual Memory is shared between the calling process and child process. That is if any of the calling process or child process modify the memory it will be visible in the other process.
2. CLONE_FS: File system attributes are shared. E.g. root directory, current working directory, file mode creation mask.
3. CLONE_FILES: If set, Parent and Child will share the table of open file descriptors. These descriptors are those values returned by open, socket, pipe etc. Modification in child will also modify the file descriptor table in parent.
4. CLONE_SIGHAND: If set, Parent and child processes will share the same signal handler table. Modification by one process will affect the other process.
5. CLONE_THREAD: Child is placed in the same thread group id as the parent. It means the pid of the parent and child will be the same, but the thread id will be different. You can get thread id by calling gettid() API.

-----
$ strace ./1_thread | grep clone
$ strace ./2_fork | grep clone
check which call use which options in clone and see how thread is fast compared to fork
-----

Theory1:
Attributes
===========

Attributes are a way to specify behavior that is different from the default.

When a thread is created with pthread_create() an attribute object can be specified. 

Note: however that the default atributes are usually sufficient for most applications.

Important Note: Attributes are specified only at thread creation time; they cannot be altered while the thread is being used.

Thus three functions are usually called in tandem

Thread attibute intialisation -- pthread_attr_init() create a default pthread_attr_t tattr
Thread attribute value change (unless defaults appropriate) -- a variety of pthread_attr_*() functions are available to set individual attribute values for the pthread_attr_t tattr structure. (see below).
Thread creation -- a call to pthread_create() with approriate attribute values set in a pthread_attr_t tattr structure.

Attributes include:
=====================
Detached or joinable state
Scheduling inheritance
Scheduling policy
Scheduling parameters
Scheduling contention scope
Stack size
Stack address
Stack guard (overflow) size

Destroying Thread Attributes
==============================

The function pthread_attr_destroy() is used to remove the storage allocated during initialization. The attribute object becomes invalid. It is prototyped by:

int pthread_attr_destroy(pthread_attr_t *tattr);

Theory2:
Calling pthread_yield api by any thread will give up the cpu to the other threads.

The current thread will be placed in the end of the run queue and another thread will be scheduled by the scheduler

Syntax: int pthread_yield(void);

Returns 0 on success and error value on error.

Theory3:
Can you fork a process with multiple threads?
=============================================

Theory4:
What is the expected output of the program?
Ans: 2*loops

If you say the above answer it is wrong, because the increment is not an atomic operation. Increment when converted to assembly will not be in single instruction.Hence the difference

One way to solve is to make increment atomic. This can be done by using atomic operator provided by GNU.

The above code suffers from a race condition - the value of i is changing. The new threads start later (in the example output the last thread starts after the loop has finished).

To overcome this race-condition, we will give each thread a pointer to it's own data area.

These are synchronization locks that are used to prevent race conditions and ensure proper synchronization between threads running in the same program

Theory5:
How many threads can you create?
===================================

With regard to threads (and processes), there are two (direct) limits that impact the number of threads that can exist at any given point in time:

	Per process resource limits: $ ulimit -u

	$prlimit --nproc

	System-wide limits: The Linux OS maintains a system-wide (not per-process) limit on the total number of threads that can be alive at any given point in time. This value is exposed to the user space via the proc filesystem:
	$ cat /proc/sys/kernel/threads-max

So, the thing to understand is that if either of the preceding two limits are breached, pthread_create(3) (and similarly, the fork(2)) will fail (typically setting errno to the value EAGAIN try again; the OS saying, in effect, "I cannot do this for you right now, please try again later").

Theory6:
Stack Location
==================

Where in memory (technically, where in the VAS of the given process) does the thread stack actually reside?

	The stack of the main thread is always situated at the very top of the process VAS.

	The stacks of all other threads in the process are located somewhere between the process heap segment and the stack of main;

Theory7:
Synchronization  in Threads
=============================

How can 50 threads run when you have only 8 cores on machine?

The answer is that the OS and threading system to arrange to multiplex the threads on the CPUs.

Each thread is given a turn on some CPU.

When it goes to do I/O, or a fixed amount of time has expired, the OS pauses the thread (saving off all of its machine state), and selects another thread to run.

It then loads the saved machine state from the new thread onto the CPU and starts that thread at the spot where it last left off (or at the beginning if it was just created).

The process of pausing one thread to run another is called pre-emption and the second thread is said to pre-empt the first. 

The process of switching to a new thread (as a result of a pre-emption event) is called context switching and the saved machine state that is necessary to get a thread running again after a pause is often called a context.

When multiple threads of control share the same memory, we need to make sure that each thread sees a consistent view of its data.

If each thread uses variables that other threads don’t read or modify, no consistency problems will exist

Similarly, if a variable is read-only, there is no consistency problem with more than one thread reading its 
value at the same time.

However, when one thread can modify a variable that other  threads can read or modify, we need to synchronize the threads to ensure that they don’t use an invalid value when accessing the variable’s memory contents.

In this example, thread A reads the variable and then writes a new value to it, but the write operation takes two memory cycles. If thread B reads the same variable between the two write cycles, it will see an inconsistent value.

    Thread A        Thread B
    ========        ========

    read

    write1

                    read

    write2

To solve this problem, the threads have to use a lock that will allow only one thread to access the variable at a time.

If it wants to read the variable, thread B acquires a lock. Similarly, when thread A updates the variable, it acquires the same lock. Thus thread B will be unable to read the variable until thread A releases the lock.

Consider the case in which we increment a variable

The increment operation is usually broken down into three steps.

    1. Read the memory location into a register.
    2. Increment the value in the register.
    3. Write the new value back to the memory location.

If two threads try to increment the same variable at almost the same time without synchronizing with each other, the results can be inconsistent.

What is a Critical Section?
=============================

A critical section is a section of code that can only be executed by one thread at a time, if the program is to function correctly.

If two threads (or processes) were to execute code inside the critical section at the same time then it is possible that program may no longer have correct behavior.

Theory8:
Mutex
============

We can protect our data and ensure access by only one thread at a time by using the pthreads mutual-exclusion interfaces

A mutex is basically a lock that we set (lock) before accessing a shared resource and release (unlock) when we’re done.

While it is set, any other thread that tries to set it will block until we release it.

If more than one thread is blocked when we unlock the mutex, then all threads blocked on the lock will be made runnable, and the first one to run will be able to set the lock.

A mutex variable is represented by the pthread_mutex_t data type.

Before we can use a mutex variable, we must first initialize it by either setting it to the constant PTHREAD_MUTEX_INITIALIZER (for statically allocated mutexes only) or calling pthread_mutex_init.

If we allocate the mutex dynamically (by calling malloc, for example), then we need to call pthread_mutex_destroy before freeing the memory.

#include <pthread.h>
int pthread_mutex_init(pthread_mutex_t *restrict mutex,
const pthread_mutexattr_t *restrict attr);
int pthread_mutex_destroy(pthread_mutex_t *mutex);

To initialize a mutex with the default attributes, we set attr to NULL.

To lock a mutex, we call pthread_mutex_lock.

If the mutex is already locked, the calling thread will block until the mutex is unlocked.

To unlock a mutex, we call pthread_mutex_unlock.

#include <pthread.h>
int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_trylock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);

If a thread can’t afford to block, it can use pthread_mutex_trylock to lock the mutex conditionally

If the mutex is unlocked at the time pthread_mutex_trylock is called, then pthread_mutex_trylock will lock the mutex without blocking and return 0.

Otherwise, pthread_mutex_trylock will fail, returning EBUSY without locking the mutex.

-------
we can find more details about mutex at [ vi /usr/include/pthread.h
-------

Deadlock
================

A thread will deadlock itself if it tries to lock the same mutex twice

When we use more than one mutex in our programs, a deadlock can occur if we allow one thread to hold a mutex and block while trying to lock a second mutex at the same time that another thread holding the second mutex tries to lock the first mutex.  Neither thread can proceed, because each needs a resource that is held by the other, so we have a deadlock.

Deadlocks can be avoided by carefully controlling the order in which mutexes are locked

For example, assume that you have two mutexes, A and B, that you need to lock at the same time

If all threads always lock mutex A before mutex B, no deadlock can occur from the use of the two mutexes

Similarly, if all threads always lock mutex B before mutex A, no deadlock will occur

You’ll have the potential for a deadlock only when one thread attempts to lock the mutexes in the opposite order from another thread.

If I lock a mutex, does it stop all other threads?
====================================================

No, the other threads will continue. It's only when a thread attempts to lock a mutex that is already locked, will the thread have to wait

Can I create mutex before fork-ing?
===================================

Yes - however the child and parent process will not share virtual memory and each one will have a mutex independent of the other.

If one thread locks a mutex can another thread unlock it?
=========================================================

No. The same thread must unlock it.

Theory9:
Debugging programs with multiple processes
=============================================

GDB provides support for debugging programs that create additional processes using the fork or vfork function.

By default, when a program forks, GDB will continue to debug the parent process and the child process will run unchecked

If you want to follow the child process instead of the parent process, use the command set follow-fork-mode. 

Syntax:
=======

set follow-fork-mode parent
set follow-fork-mode child
show follow-fork-mode
Default mode:-
The default value for the follow-fork-mode setting is 'parent'.

Debugging programs with multiple processes
=============================================
On Linux, if you want to debug both the parent and child processes, use the command set detach-on-fork.

Syntax: set detach-on-fork mode

Tells gdb whether to detach one of the processes after a fork, or retain debugger control over them both.

on
	The child process (or parent process, depending on the value of follow-fork-mode) will be detached and allowed to run independently. This is the default.

off
	Both processes will be held under the control of GDB. One process (child or parent, depending on the value of follow-fork-mode) is debugged as usual, while the other is held suspended.

show detach-on-fork
	Show whether detach-on-fork mode is on/off.

If you choose to set ‘detach-on-fork’ mode off, then GDB will retain control of all forked processes 

You can list the forked processes under the control of GDB by using the info inferiors command, and switch from one fork to another by using the inferior command

To quit debugging one of the forked processes, you can either detach from it by using the detach inferiors command (allowing it to run independently)

Debugging Threads using gdb
=============================

How to List all active threads?
“info threads”

The currently active thread is denoted by GDB with the * symbol. 

How to Switch between threads while debugging?
===============================================

In GDB, the thread command may be used to switch between threads. It takes a single parameter, the thread number returned by the info threads command. 

(gdb) thread <Thread Number>
(gdb) thread 2
(gdb) thread 1

Notification on Thread Creation
===============================

When GDB detects that a new thread is created, it displays a message specifying the thread's identification on the current system. 

Setting Thread-Specific Breakpoints
=====================================

GDB allows users that are debugging multithreaded applications to choose whether or not to set a breakpoint on all threads or on a particular thread. 

The general form of this instruction is: 

break linespec thread threadnum

break file.c:33 thread 7 if level > max_level

Applying a Command to a Group of Threads
========================================

The thread command supports a single subcommand apply that can be used to apply a command to one or more threads in the application.

The thread numbers can be supplied individually, or the special keyword all may be used to apply the command to all threads in the process,

(gdb) thread apply all bt

The GDB backtrace (bt) command is applied to all threads in the system.

Helgrind
=============

Helgrind is a Valgrind tool for detecting synchronisation errors in C, C++ and Fortran programs that use the POSIX pthreads threading primitives.

Helgrind can detect three classes of errors
	1.Misuses of the POSIX pthreads API.

	2.Potential deadlocks arising from lock ordering problems.

	3.Data races -- accessing memory without adequate locking or synchronisation.

$ valgrind --tool=helgrind ./app

GCC Thread Sanitizer
=========================

Thread Sanitizer (TSAN, -fsanitize=thread): detect data races in multi-threaded programs.

-g -fsanitize=thread

Theory10:
What is the Reader Writer Problem?
==================================

There is a shared resource which should be accessed by multiple processes. 

There are two types of processes in this context. They are reader and writer.

Any number of readers can read from the shared resource simultaneously, but only one writer can write to the shared resource.

When a writer is writing data to the resource, no other process can access the resource

A writer cannot write to the resource if there are non zero number of readers accessing the resource at that time.

read() {
  lock(&m)
  // do read stuff
  unlock(&m)
}

write() {
  lock(&m)
  // do write stuff
  unlock(&m)
}

At least our first attempt does not suffer from data corruption (readers must wait while a writer is writing and vice versa)! 

However readers must also wait for other readers.

Reader-Writer Locks
===================

Reader–writer locks are similar to mutexes, except that they allow for higher degrees of parallelism.

With a mutex, the state is either locked or unlocked, and only one thread can lock it at a time.

Three states are possible with a reader–writer lock: 
	locked in read mode, 
	locked in write mode, and 
	unlocked.

Only one thread at a time can hold a reader–writer lock in write mode, but multiple threads can hold a reader–writer lock in read mode at the same time

When a reader–writer lock is write locked, all threads attempting to lock it block until it is unlocked.

When a reader–writer lock is read locked, all threads attempting to lock it in read mode are given access, but any threads attempting to lock it in write mode block until all the threads have released their read locks

Reader–writer locks are well suited for situations in which data structures are read more often than they are modified

Reader–writer locks are also called shared–exclusive locks. When a reader–writer lock is read locked, it is said to be locked in shared mode. When it is write locked, it is said to be locked in exclusive mode.

As with mutexes, reader–writer locks must be initialized before use and destroyed before freeing their underlying memory.

#include <pthread.h>
int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,
const pthread_rwlockattr_t *restrict attr);
int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
Both return: 0 if OK, error number on failure

A reader–writer lock is initialized by calling pthread_rwlock_init. We can pass a null pointer for attr if we want the reader–writer lock to have the default attributes

Before freeing the memory backing a reader–writer lock, we need to call pthread_rwlock_destroy to clean it up.

To lock a reader–writer lock in read mode, we call pthread_rwlock_rdlock. To  write lock a reader–writer lock, we call pthread_rwlock_wrlock. Regardless of how we lock a reader–writer lock, we can unlock it by calling pthread_rwlock_unlock.

#include <pthread.h>
int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
